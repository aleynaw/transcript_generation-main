{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, json, glob, random\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DM_transcript_dir = \"./transcripts/gpt4/DM\"\n",
    "SM_transcript_dir = \"./transcripts/gpt4/SM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_dir = Path(\"./training_data\")\n",
    "training_data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "#used during training\n",
    "eval_data_dir = Path(training_data_dir, \"evaluation_data\")\n",
    "eval_data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "#used to test model after training\n",
    "test_data_dir = Path(training_data_dir, \"test_data\")\n",
    "test_data_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_prompt_path = 'prompts/double_model_prompts/patient_prompt.txt'\n",
    "asst_prompt_path ='prompts/double_model_prompts/assistant_prompt.txt'\n",
    "questions_path = 'prompts/questionbank.txt'\n",
    "\n",
    "with open(questions_path, \"r\") as f:\n",
    "    questions_str1 = f.read().replace(\"\\n\", \"\\\\n\")\n",
    "\n",
    "print(questions_str1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_str = Path(questions_path).read_text()\n",
    "print(questions_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "thoughts about using previous history in the training itself:\n",
    "- need to account for context size-- should only append certain number of past messages or the context window will be too large\n",
    "- need to account for the chat history? maybe store a list of past messages and write some other code that transforms it into the desired chat model's past history format\n",
    "    - to do this i should also update the textgen formatting dictionary...\n",
    "'''\n",
    "def process_data_with_history(input_files):\n",
    "    ''':input_files: (list)'''\n",
    "    def append_history(msg_list):\n",
    "        pass ##TODO: implement gradual addition\n",
    "    # Load the data from the original JSON file\n",
    "    \n",
    "    # Prepare the new dataset\n",
    "    new_dataset = []\n",
    "    current_pair = {}\n",
    "    for input_file in input_files:\n",
    "        with open(input_file, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        \n",
    "        # append_history(msg_list) ##TODO: implement\n",
    "        # Iterate through the list of dictionaries\n",
    "        for item in data[1:]:\n",
    "            if item['role'] == 'user':\n",
    "                current_pair['user'] = item['content']\n",
    "            elif item['role'] == 'assistant':\n",
    "                current_pair['assistant'] = item['content']\n",
    "                # Make sure both user and assistant messages are present\n",
    "                if 'user' in current_pair and 'assistant' in current_pair:\n",
    "                    new_dataset.append(current_pair)\n",
    "                    current_pair = {}\n",
    "    \n",
    "    return new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(input_files):\n",
    "    ''':input_files: (list)'''\n",
    "    # Load the data from the original JSON file\n",
    "    \n",
    "    # Prepare the new dataset\n",
    "    new_dataset = []\n",
    "    current_pair = {}\n",
    "    for input_file in input_files:\n",
    "        with open(input_file, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        \n",
    "        # Iterate through the list of dictionaries\n",
    "        for item in data[1:]: #do not include the assistant intro message\n",
    "            if item['role'] == 'user':\n",
    "                current_pair['user'] = item['content']\n",
    "            elif item['role'] == 'assistant':\n",
    "                current_pair['assistant'] = item['content']\n",
    "                # Make sure both user and assistant messages are present\n",
    "                if 'user' in current_pair and 'assistant' in current_pair:\n",
    "                    new_dataset.append(current_pair)\n",
    "                    current_pair = {}\n",
    "    \n",
    "    return new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "dm_json_files = glob.glob(DM_transcript_dir+\"/*.json\")\n",
    "print(dm_json_files)\n",
    "\n",
    "sm_json_files = glob.glob(SM_transcript_dir+\"/*.json\")\n",
    "print(sm_json_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do we want to use fraction of all transcripts as the evaluation set (evaluation set comprised of complete, full transcript)?\n",
    "- to do this: randomize the order of the json files -> select fraction -> call process_data separately\n",
    "or do we want to use fraction of all json pairings (evaluation set comprised of random pairings)?\n",
    "- to do this: call process_data -> randomize -> select fractions\n",
    "currently implements the second type with test/evaluation sets compromising 15% of the pairings. my logic is that each pairing is trained independently anyway, so there shouldn't be as much of an influence..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_dataset = process_data(dm_json_files)\n",
    "\n",
    "divider = int(len(dm_dataset)*0.15) #15% of the dataset will be used for training\n",
    "print(divider)\n",
    "\n",
    "random.shuffle(dm_dataset)\n",
    "\n",
    "eval_dataset = dm_dataset[:divider] #first 15%\n",
    "test_dataset = dm_dataset[divider:divider+divider] #second 15%\n",
    "training_dataset = dm_dataset[divider+divider:] #the rest 70% of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(eval_dataset), len(test_dataset), len(training_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = str(training_data_dir)+f'/{Path(DM_transcript_dir).stem}_{datetime.now().strftime(\"%Y%m%d\")}_{len(training_dataset)}i.json'\n",
    "\n",
    "eval_file = str(eval_data_dir)+f'/{Path(DM_transcript_dir).stem}_{datetime.now().strftime(\"%Y%m%d\")}_{len(eval_dataset)}i.json'\n",
    "\n",
    "test_file = str(test_data_dir)+f'/{Path(DM_transcript_dir).stem}_{datetime.now().strftime(\"%Y%m%d\")}_{len(test_dataset)}i.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_file, 'w') as file:\n",
    "    json.dump(training_dataset, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the new dataset to a new JSON file\n",
    "with open(eval_file, 'w') as file:\n",
    "    json.dump(eval_dataset, file, indent=4)\n",
    "\n",
    "with open(test_file, 'w') as file:\n",
    "    json.dump(test_dataset, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## do the same for single model transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_dataset = process_data(sm_json_files)\n",
    "\n",
    "output_file = str(training_data_dir)+f'/{Path(SM_transcript_dir).stem}_{datetime.now().strftime(\"%Y%m%d\")}_{len(sm_dataset)}i.json'\n",
    "eval_file = str(eval_data_dir)+f'/{Path(DM_transcript_dir).stem}_{datetime.now().strftime(\"%Y%m%d\")}_{len(dm_dataset)}i.json'\n",
    "\n",
    "# Save the new dataset to a new JSON file\n",
    "with open(output_file, 'w') as file:\n",
    "    json.dump(sm_dataset, file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "locllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
