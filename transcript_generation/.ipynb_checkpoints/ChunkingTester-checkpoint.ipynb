{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2a4c129-b2ba-4768-88c5-5c91e83118c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, csv, ast, random, time\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import time\n",
    "from collections import deque  # Queue for questions\n",
    "import re\n",
    "\n",
    "##### Prompt templates\n",
    "starter_path = 'prompts/starter.txt'\n",
    "questions_path = 'prompts/questions_test/Analysis/questionbank_chunked.txt'\n",
    "patient_prompt_path = 'prompts/double_model_prompts/INSTRUCT/patient_prompt_v1.txt'\n",
    "asst_prompt_path = 'prompts/double_model_prompts/INSTRUCT/assistant_prompt_v2.txt'\n",
    "tracking_path = \"./tracking.csv\"\n",
    "\n",
    "##### directory for interview outputs\n",
    "out_dir = \"transcripts/DM\"\n",
    "\n",
    "try:\n",
    "    sys.path.append('../../transcript_creation')\n",
    "    from transcript_creation import helper_fns as helper\n",
    "except ModuleNotFoundError:\n",
    "    import helper_fns as helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a997ef6a-0797-40da-9b60-f52e42f09e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "# HELPER FUNCTIONS\n",
    "##############################\n",
    "\n",
    "def update_msg_list(message_list, is_assistant, content):\n",
    "    role = \"assistant\" if is_assistant else \"user\"\n",
    "    message_list.append({\"role\": role, \"content\": content})\n",
    "    return message_list\n",
    "\n",
    "def swap_msg_list(message_list):\n",
    "    '''Return the message list with Assistant/User role labels inversed.'''\n",
    "    swapped_msg_list = []\n",
    "    for msg in message_list:\n",
    "        if msg[\"role\"] == \"assistant\":\n",
    "            swapped_msg_list.append({\n",
    "                \"role\": \"user\",\n",
    "                \"content\": msg[\"content\"]\n",
    "            })\n",
    "        if msg[\"role\"] == \"user\":\n",
    "            swapped_msg_list.append({\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": msg[\"content\"]\n",
    "            })\n",
    "    return swapped_msg_list\n",
    "\n",
    "def extract_response_text(response):\n",
    "    \"\"\"\n",
    "    Extract the portion of the response after 'RESPONSE:'.\n",
    "    If 'RESPONSE:' is not found, return the whole response.\n",
    "    \"\"\"\n",
    "    split_key = \"RESPONSE:\"\n",
    "    if split_key in response:\n",
    "        return response.split(split_key)[-1].strip()  # Take everything after 'RESPONSE:'\n",
    "    else:\n",
    "        return response.strip()  # Return the whole response if 'RESPONSE:' is missing\n",
    "\n",
    "def extract_and_store_notes(response, notes):\n",
    "    \"\"\"\n",
    "    Extracts 'Notes' from the response and appends them to the notes string.\n",
    "    \"\"\"\n",
    "    if \"Notes:\" in response:\n",
    "        note_start = response.find(\"Notes:\")\n",
    "        note_end = response.find(\"\\n\", note_start)\n",
    "        notes += response[note_start:note_end].strip() + \"\\n\"\n",
    "    return notes\n",
    "\n",
    "def chunk_message_history(message_list, max_history_size=10):\n",
    "    \"\"\"\n",
    "    Trims the message list to only keep the most recent `max_history_size` messages.\n",
    "    \"\"\"\n",
    "    if len(message_list) > max_history_size:\n",
    "        message_list = message_list[-max_history_size:]  # Keep only the most recent messages\n",
    "    return message_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58b2bf5f-e60d-4361-9ba3-0d1921b0c12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "# NEW QUESTION PARSING FUNCTIONS\n",
    "##############################\n",
    "\n",
    "def parse_questions_with_headers(question_text):\n",
    "    \"\"\"\n",
    "    Parses the questions with headers into a structured list, preserving the hierarchy.\n",
    "    Returns a list of sections, where each section is a list that includes both the headers and their associated questions.\n",
    "    \"\"\"\n",
    "    lines = question_text.splitlines()\n",
    "    current_section = []\n",
    "    current_subsection = []\n",
    "    sections = []\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()  # Clean up any extra spaces\n",
    "        if line.startswith(\"##\"):  # Section header\n",
    "            if current_section:\n",
    "                sections.append(current_section)\n",
    "            current_section = [line]  # Start new section\n",
    "        elif line.startswith(\"#\"):  # Subheader\n",
    "            if current_subsection:\n",
    "                current_section.append(current_subsection)\n",
    "            current_subsection = [line]  # Start new subsection\n",
    "        elif line.startswith(\"-\") or line.startswith(\"+\"):  # Question or continuation\n",
    "            current_subsection.append(line)  # Add to current subsection\n",
    "\n",
    "    # Add the final section and subsection\n",
    "    if current_subsection:\n",
    "        current_section.append(current_subsection)\n",
    "    if current_section:\n",
    "        sections.append(current_section)\n",
    "    \n",
    "    return sections\n",
    "\n",
    "def chunk_questions(sections):\n",
    "    \"\"\"\n",
    "    Chunk the questions into a list of lists, where each sublist contains\n",
    "    questions from a specific sub-section. Each list starts with the \n",
    "    section title and subheader as the first entry, followed by the questions.\n",
    "    \"\"\"\n",
    "    chunked_questions = []\n",
    "\n",
    "    for section in sections:\n",
    "        section_title = section[0]  # Get the main section title\n",
    "        \n",
    "        for sub_section in section[1:]:\n",
    "            sub_section_title = sub_section[0]  # Get the sub-header title\n",
    "            sub_section_chunks = [f\"{section_title} {sub_section_title}\"]  # Start with combined title\n",
    "            \n",
    "            # Add the first question if it exists\n",
    "            if len(sub_section) > 1:\n",
    "                first_question = sub_section[1]\n",
    "                sub_section_chunks = [f\"{section_title} {sub_section_title} {first_question}\"]\n",
    "            \n",
    "            # Add the rest of the questions in the sub-section\n",
    "            for question in sub_section[2:]:\n",
    "                sub_section_chunks.append(question)\n",
    "            \n",
    "            # Append this sub-section's chunk of questions to the overall list\n",
    "            chunked_questions.append(sub_section_chunks)\n",
    "\n",
    "    return chunked_questions\n",
    "\n",
    "\n",
    "def queue_questions(chunks, questions_queue, num_questions_to_add=2):\n",
    "    \"\"\"\n",
    "    Adds a set number of questions from the chunks to the queue, ensuring headers are preserved.\n",
    "    \"\"\"\n",
    "    while len(questions_queue) < num_questions_to_add and chunks:\n",
    "        chunk = chunks.pop(0)\n",
    "        questions_queue.extend(chunk)  # Add chunk to queue\n",
    "    return questions_queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70b55530-3a49-422e-8d6b-b6a23bd61ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "# CONVERSATION FUNCTION\n",
    "##############################\n",
    "\n",
    "def chat_between_models(message_list, asst_prompt, patient_prompt, starter):\n",
    "    # Conduct the interview between two models until <STOP> condition is reached\n",
    "    # Read questions from the file as a single string\n",
    "    \n",
    "    questions = Path(questions_path).read_text()  # This should read the content as a string\n",
    "    sections = parse_questions_with_headers(questions)  # Pass the string directly\n",
    "    # print(\"Sections:\", sections)  # Print sections for debugging\n",
    "    chunks = chunk_questions(sections)  # Get the structured chunks of questions\n",
    "    # print(\"Chunks:\", chunks)  # Print chunks for debugging\n",
    "    \n",
    "    max_history_size = 10  # Define the size of message history chunks\n",
    "    notes = \"\"  # Initialize notes storage\n",
    "    max_turns = 50\n",
    "    current_chunk_idx = 0  # Start at the first chunk\n",
    "    questions_queue = deque()  # Initialize a queue for questions\n",
    "    transcript = []\n",
    "\n",
    "        \n",
    "    for i in chunks:\n",
    "        print(i)\n",
    "        questions_queue.append(i)\n",
    "\n",
    "    stop_condition = False\n",
    "    turns = 0\n",
    "    prev_chunk_length = 0\n",
    "    total_chunk_lengths = 0\n",
    "    start = time.time()\n",
    "    \n",
    "    first_chunk_complete = 0\n",
    "    \n",
    "    first_chunk = questions_queue.popleft()\n",
    "    curr_chunk = first_chunk\n",
    "    questions_list = curr_chunk\n",
    "    formatted_questions_list = '\\n'.join(first_chunk)\n",
    "\n",
    "    while not stop_condition and turns < max_turns:\n",
    "        time.sleep(1)\n",
    "        \n",
    "        \n",
    "        curr_chunk_length = len(curr_chunk)\n",
    "        print(\"Question amount: \", curr_chunk_length)\n",
    "        \n",
    "        print(\"if turns == \", curr_chunk_length, \" + \", total_chunk_lengths)\n",
    "        if turns == curr_chunk_length + total_chunk_lengths:\n",
    "            \n",
    "            print(\"Next chunk: \", questions_queue[0])\n",
    "            next_question_chunk = questions_queue.popleft()\n",
    "            \n",
    "            if first_chunk_complete:\n",
    "                print()\n",
    "                print(\"Dumping first questions.........................................................\")\n",
    "                i=0\n",
    "                while i < prev_chunk_length:\n",
    "                    print(\"Dumping \", prev_chunk[i])\n",
    "                    questions_list.pop(0)\n",
    "                    print(questions_list)\n",
    "                    i += 1\n",
    "                    \n",
    "                print(\"Saving and dumping previous messages..............................................\")\n",
    "                i=0\n",
    "                while i < prev_chunk_length*2:\n",
    "                    print(\"Saving \", message_list[i])\n",
    "                    transcript.append(message_list[0])\n",
    "                    message_list.pop(0)\n",
    "                    for message in transcript:\n",
    "                        print(message[\"content\"])\n",
    "                    print(\"Message_list length: \", len(message_list))\n",
    "                    i+=1\n",
    "            \n",
    "            prev_chunk_length = curr_chunk_length\n",
    "            total_chunk_lengths = total_chunk_lengths + curr_chunk_length\n",
    "            prev_chunk = curr_chunk\n",
    "            curr_chunk = next_question_chunk\n",
    "            \n",
    "            \n",
    "            questions_list = questions_list + curr_chunk\n",
    "            formatted_questions_list = '\\n'.join(questions_list)\n",
    "            print(\"Formatted questions: \", '\\n', formatted_questions_list)\n",
    "            print(\"Updating assistant prompt...\")\n",
    "            \n",
    "            first_chunk_complete = 1\n",
    "            \n",
    "    \n",
    "            \n",
    "            \n",
    "                \n",
    "            \n",
    "            \n",
    "        asst_prompt_with_questions = asst_prompt.replace(r\"{questions}\", formatted_questions_list)\n",
    "        # print(\"Assistant prompt with questions:\", '\\n', asst_prompt_with_questions)  # Debug print\n",
    "\n",
    "        # Simulating the patient model's response\n",
    "        patient_response = \"<Patient responds to chunk questions>\"\n",
    "        print(f\"Patient response (turn {turns}):\\n\", patient_response)\n",
    "        \n",
    "        # Simulating assistant's response (taking notes on the questions)\n",
    "        assistant_response = \"<Assistant asks questions and adds notes>\"\n",
    "        print(f\"Assistant response (turn {turns}):\\n\", assistant_response)\n",
    "            \n",
    "        \n",
    "            \n",
    "        # Add both assistant and patient responses to message list\n",
    "        message_list.append({\n",
    "             'role': 'user', 'content': patient_response\n",
    "         })\n",
    "            \n",
    "        message_list.append({\n",
    "             'role': 'assistant', 'content': assistant_response,\n",
    "         })\n",
    "            \n",
    "        # Chunk the message history\n",
    "        turns += 1\n",
    "        print(\"Turn count:\", turns)\n",
    "\n",
    "        if not questions_queue:\n",
    "            stop_condition = True\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "    end = time.time()\n",
    "    time_taken = end - start\n",
    "    print(\"INTERVIEW HAS ENDED\")\n",
    "    print(\"SYSTEM: \")\n",
    "    print(\"Total time taken:\", time_taken)\n",
    "    print(\"Final Notes:\", notes)  # Print or return final notes\n",
    "    return message_list, notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7380234-7ef1-431e-a0e3-e279521a11aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interview_gen(patient: dict, output_id: str, out_dir=out_dir, tracking_path=tracking_path):\n",
    "    \"\"\"\n",
    "    Creates interviews based on the patients that are passed in.\n",
    "    \"\"\"\n",
    "    Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    ##### Prompt templates\n",
    "    patient_prompt_str = Path(patient_prompt_path).read_text()\n",
    "    asst_prompt_str = Path(asst_prompt_path).read_text()\n",
    "    starter_str = Path(starter_path).read_text()\n",
    "\n",
    "    ### hydrate starter\n",
    "    clinician_name = patient[\"Clinician Name\"]\n",
    "    appt_date = patient[\"Appointment Date\"]\n",
    "    starter = starter_str.replace(r\"{Clinician Name}\", clinician_name)\n",
    "    starter = starter.replace(r\"{Date}\", appt_date)\n",
    "\n",
    "    ### hydrate patient prompt\n",
    "    if \"Edge Case Scenario\" in patient:  # if there is an edge case\n",
    "        edge_case = patient[\"Edge Case Scenario\"]\n",
    "        patient_prompt_str = patient_prompt_str.replace(r\"{edge_case_scenario}\", f\"\\n\\n{edge_case}\")\n",
    "        ignore_keys = [\"Clinician Name\", \"Appointment Date\", 'Conversational Tone', 'Reason for Appointment']\n",
    "    else:  # if there is no edge case\n",
    "        edge_case = \"\"\n",
    "        patient_prompt_str = patient_prompt_str.replace(r\"{edge_case_scenario}\", \"\")\n",
    "        ignore_keys = [\"Clinician Name\", \"Appointment Date\", 'Conversational Tone', \"Edge Case Scenario\", 'Reason for Appointment']\n",
    "    \n",
    "    patient_string = helper.patient_to_str(patient, ignore_keys)\n",
    "    patient_prompt = patient_prompt_str.replace(r\"{patient_info}\", patient_string)\n",
    "\n",
    "    ### begin with starter message\n",
    "    message_list_starter = [\n",
    "        {\"role\": \"assistant\", \"content\": starter}\n",
    "    ]\n",
    "    message_list = message_list_starter\n",
    "    \n",
    "    # Run the chat\n",
    "    conversation, notes = chat_between_models(message_list, asst_prompt_str, patient_prompt, starter)\n",
    "    for message in conversation:\n",
    "        print(message[\"content\"])\n",
    "\n",
    "    # Use the final notes at the end of the conversation\n",
    "    print(\"Final notes summary: \", notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2351caf8-0d42-45c1-8c14-5c8432611954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\n",
      "0 Oscar Webb\n",
      "['## General Information ## # Personal Information - full name', '- preferred name', '- date of birth', '- sex', '- handedness: left, right, both']\n",
      "['## General Information ## # Residence and Marital Status - current city/town of residence', '- single, married, or common law?', '- any children or dependents?', '+ if yes, names and ages?']\n",
      "['## General Information ## # Employment and Financial Status - currently working?', '+ if yes, name of company? years working?', '- disability assistance status', '+ if yes, what type and when?']\n",
      "['## General Information ## # Medical Care Information - current doctors?', '- allergies', '- current medications and dosage?', '- health supplements']\n",
      "['## Medical History ## # Substance Use - frequency of nicotine, marijuana, alcohol use?']\n",
      "['## Medical History ## # General Health - health conditions/diagnoses and details such as when you were diagnosed?', '- previous hospitalizations, surgeries']\n",
      "['## Medical History ## # Neurological and Mental Health - history of head injuries/concussions', '+ if yes, when and how?', '- history of seizures', '+ if yes, when it started?', '- history of rehab or substance counselling', '+ if yes, where? when?']\n",
      "['## Family History ## # Professional Care - other medical professionals seen', '+ if yes, who/when/why?']\n",
      "['## Family History ## # Mental and Neurological Health - history of psychiatric conditions in other family members', '+ if yes, who? did they receive treatment or hospital care?', '- family history of neurological or genetic conditions', '+ if yes, who? did they receive treatment or hospital care?']\n",
      "['## Personal History ## # Siblings - siblings', \"+ if yes, ask for each sibling's basic info such as name, age, where they live, occupation\"]\n",
      "['## Personal History ## # Early Life and Citizenship - where were you born?', '+ if outside canada, year of arrival?', '- are you a canadian citizen?', '- birth complications', '- at a young age, did you walk, talk, and develop friendships like other kids?']\n",
      "['## Personal History ## # Education - difficulties in elementary school', '- average mark and favorite topic/class in high school', '- further education after high school', '+ if yes, where and what type of studies?']\n",
      "['## Personal History ## # Employment and Relationships - previous work history', '+ if yes, companies and years of work?', '- any previous marriages/long term relationships']\n",
      "['## Additional Comments ## # Hobbies and Lifestyle - hobbies', '- what do you do to relax on a stressful day?']\n",
      "['## Additional Comments ## # Final Thoughts - anything the doctor needs to know', '- no more questions, end interview']\n",
      "Question amount:  5\n",
      "if turns ==  5  +  0\n",
      "Patient response (turn 0):\n",
      " <Patient responds to chunk questions>\n",
      "Assistant response (turn 0):\n",
      " <Assistant asks questions and adds notes>\n",
      "Turn count: 1\n",
      "Question amount:  5\n",
      "if turns ==  5  +  0\n",
      "Patient response (turn 1):\n",
      " <Patient responds to chunk questions>\n",
      "Assistant response (turn 1):\n",
      " <Assistant asks questions and adds notes>\n",
      "Turn count: 2\n",
      "Question amount:  5\n",
      "if turns ==  5  +  0\n",
      "Patient response (turn 2):\n",
      " <Patient responds to chunk questions>\n",
      "Assistant response (turn 2):\n",
      " <Assistant asks questions and adds notes>\n",
      "Turn count: 3\n",
      "Question amount:  5\n",
      "if turns ==  5  +  0\n",
      "Patient response (turn 3):\n",
      " <Patient responds to chunk questions>\n",
      "Assistant response (turn 3):\n",
      " <Assistant asks questions and adds notes>\n",
      "Turn count: 4\n",
      "Question amount:  5\n",
      "if turns ==  5  +  0\n",
      "Patient response (turn 4):\n",
      " <Patient responds to chunk questions>\n",
      "Assistant response (turn 4):\n",
      " <Assistant asks questions and adds notes>\n",
      "Turn count: 5\n",
      "Question amount:  5\n",
      "if turns ==  5  +  0\n",
      "Next chunk:  ['## General Information ## # Residence and Marital Status - current city/town of residence', '- single, married, or common law?', '- any children or dependents?', '+ if yes, names and ages?']\n",
      "Formatted questions:  \n",
      " ## General Information ## # Personal Information - full name\n",
      "- preferred name\n",
      "- date of birth\n",
      "- sex\n",
      "- handedness: left, right, both\n",
      "## General Information ## # Residence and Marital Status - current city/town of residence\n",
      "- single, married, or common law?\n",
      "- any children or dependents?\n",
      "+ if yes, names and ages?\n",
      "Updating assistant prompt...\n",
      "Patient response (turn 5):\n",
      " <Patient responds to chunk questions>\n",
      "Assistant response (turn 5):\n",
      " <Assistant asks questions and adds notes>\n",
      "Turn count: 6\n",
      "Question amount:  4\n",
      "if turns ==  4  +  5\n",
      "Patient response (turn 6):\n",
      " <Patient responds to chunk questions>\n",
      "Assistant response (turn 6):\n",
      " <Assistant asks questions and adds notes>\n",
      "Turn count: 7\n",
      "Question amount:  4\n",
      "if turns ==  4  +  5\n",
      "Patient response (turn 7):\n",
      " <Patient responds to chunk questions>\n",
      "Assistant response (turn 7):\n",
      " <Assistant asks questions and adds notes>\n",
      "Turn count: 8\n",
      "Question amount:  4\n",
      "if turns ==  4  +  5\n",
      "Patient response (turn 8):\n",
      " <Patient responds to chunk questions>\n",
      "Assistant response (turn 8):\n",
      " <Assistant asks questions and adds notes>\n",
      "Turn count: 9\n",
      "Question amount:  4\n",
      "if turns ==  4  +  5\n",
      "Next chunk:  ['## General Information ## # Employment and Financial Status - currently working?', '+ if yes, name of company? years working?', '- disability assistance status', '+ if yes, what type and when?']\n",
      "\n",
      "Dumping first questions.........................................................\n",
      "Dumping  ## General Information ## # Personal Information - full name\n",
      "['- preferred name', '- date of birth', '- sex', '- handedness: left, right, both', '## General Information ## # Residence and Marital Status - current city/town of residence', '- single, married, or common law?', '- any children or dependents?', '+ if yes, names and ages?']\n",
      "Dumping  - preferred name\n",
      "['- date of birth', '- sex', '- handedness: left, right, both', '## General Information ## # Residence and Marital Status - current city/town of residence', '- single, married, or common law?', '- any children or dependents?', '+ if yes, names and ages?']\n",
      "Dumping  - date of birth\n",
      "['- sex', '- handedness: left, right, both', '## General Information ## # Residence and Marital Status - current city/town of residence', '- single, married, or common law?', '- any children or dependents?', '+ if yes, names and ages?']\n",
      "Dumping  - sex\n",
      "['- handedness: left, right, both', '## General Information ## # Residence and Marital Status - current city/town of residence', '- single, married, or common law?', '- any children or dependents?', '+ if yes, names and ages?']\n",
      "Dumping  - handedness: left, right, both\n",
      "['## General Information ## # Residence and Marital Status - current city/town of residence', '- single, married, or common law?', '- any children or dependents?', '+ if yes, names and ages?']\n",
      "Saving and dumping previous messages..............................................\n",
      "Saving  {'role': 'assistant', 'content': 'Good day, I am Dr. Tami Hamiltonâ€™s Interview Assistant and I was asked to connect with you before your appointment on November 9 at the medical clinic. My goal is to gather some background information for the doctor.\\nI am an AI Assistant and in compliance with confidentiality regulations (BC Protection of Privacy), the data transmission for this interview and analysis is located in Canada, and all information I gather will be stored privately and only available for Dr. Tami Hamilton to review. Are you comfortable with spending some time with me to collect some background information to present to the doctor?'}\n",
      "Good day, I am Dr. Tami Hamiltonâ€™s Interview Assistant and I was asked to connect with you before your appointment on November 9 at the medical clinic. My goal is to gather some background information for the doctor.\n",
      "I am an AI Assistant and in compliance with confidentiality regulations (BC Protection of Privacy), the data transmission for this interview and analysis is located in Canada, and all information I gather will be stored privately and only available for Dr. Tami Hamilton to review. Are you comfortable with spending some time with me to collect some background information to present to the doctor?\n",
      "Message_list length:  18\n",
      "Saving  {'assistant': '<Assistant asks questions and adds notes>'}\n",
      "Good day, I am Dr. Tami Hamiltonâ€™s Interview Assistant and I was asked to connect with you before your appointment on November 9 at the medical clinic. My goal is to gather some background information for the doctor.\n",
      "I am an AI Assistant and in compliance with confidentiality regulations (BC Protection of Privacy), the data transmission for this interview and analysis is located in Canada, and all information I gather will be stored privately and only available for Dr. Tami Hamilton to review. Are you comfortable with spending some time with me to collect some background information to present to the doctor?\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'content'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m patient_dict \u001b[38;5;241m=\u001b[39m patient\u001b[38;5;241m.\u001b[39mdropna()\u001b[38;5;241m.\u001b[39mto_dict()\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(i, patient_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m---> 23\u001b[0m \u001b[43minterview_gen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatient_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./transcripts/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfolder_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/DM\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \n",
      "Cell \u001b[1;32mIn[5], line 38\u001b[0m, in \u001b[0;36minterview_gen\u001b[1;34m(patient, output_id, out_dir, tracking_path)\u001b[0m\n\u001b[0;32m     35\u001b[0m message_list \u001b[38;5;241m=\u001b[39m message_list_starter\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Run the chat\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m conversation, notes \u001b[38;5;241m=\u001b[39m \u001b[43mchat_between_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43masst_prompt_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatient_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m conversation:\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28mprint\u001b[39m(message[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Cell \u001b[1;32mIn[4], line 70\u001b[0m, in \u001b[0;36mchat_between_models\u001b[1;34m(message_list, asst_prompt, patient_prompt, starter)\u001b[0m\n\u001b[0;32m     68\u001b[0m message_list\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m transcript:\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mmessage\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessage_list length: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(message_list))\n\u001b[0;32m     72\u001b[0m i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'content'"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "print(Path.cwd())\n",
    "\n",
    "### read the patients csv\n",
    "patients_path = Path(\"../patient_creation/patients.csv\")\n",
    "patients_df = pd.read_csv(patients_path,delimiter=\"|\")\n",
    "\n",
    "folder_name = \"llama3.1\"\n",
    "Path.mkdir(Path(Path.cwd(), \"transcripts\", folder_name), exist_ok=True)\n",
    "\n",
    "for i, patient in patients_df.iterrows():\n",
    "\n",
    "    #### use the code below instead if you want to generate a transcript for a certain patient\n",
    "    if i == 0:\n",
    "        output_id = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        patient_dict = patient.dropna().to_dict()\n",
    "        print(i, patient_dict[\"Name\"])\n",
    "        interview_gen(patient=patient_dict, output_id=output_id, out_dir=f\"./transcripts/{folder_name}/DM\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95724c09-2d09-4dde-bb7d-687ac50edef4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llm)",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
