{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cb24ccb-fe1b-4d15-b5d7-e668d26be979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import random\n",
    "import time\n",
    "\n",
    "from openai import OpenAI\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42944d82-bf45-4d0f-a599-bf79629e0dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Langchain and Ollama\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "model1 = OllamaLLM(base_url=\"localhost:11435\", \n",
    "                  model=\"llama3.1:70b-instruct-q4_0\", \n",
    "                  temperature=0.5, \n",
    "                  num_ctx = 6144,\n",
    "                  top_k = 40,\n",
    "                  top_p = 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ece24d2b-6630-4fd2-8647-322efb54e80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llama_response(messages_list):\n",
    "    '''obtain response from llama'''\n",
    "\n",
    "    response = model1.invoke(messages_list)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74e88cad-9dc2-4555-8a22-d5ad40052e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coverage(coverage_prompt):\n",
    "    \n",
    "    # Call the local LLaMA model instead of OpenAI's API\n",
    "    content = get_llama_response(coverage_prompt)\n",
    "    \n",
    "    try:\n",
    "        specificity_val = int(content.split(\"### Score\")[-1][:4].strip())\n",
    "    except ValueError:\n",
    "        specificity_val = np.NaN\n",
    "    \n",
    "    return content, specificity_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "091f6410-daad-4d1a-88eb-c2097e649800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent Directory: C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "import sys, os, csv, ast, random, time, re, json\n",
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "patients_path = Path(r\"C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\patient_creation\\llm_patients.csv\")\n",
    "patients_df = pd.read_csv(patients_path,delimiter=\"|\")\n",
    "# print(patients_df)\n",
    "\n",
    "parent_directory = Path.cwd().resolve().parent.parent.parent.parent\n",
    "print(f\"Parent Directory: {parent_directory}\")\n",
    "\n",
    "sys.path.append(str(parent_directory))\n",
    "\n",
    "try:\n",
    "    sys.path.append('../../transcript_generation')\n",
    "    from transcript_generation import helper_fns as helper\n",
    "except ModuleNotFoundError:\n",
    "    import helper_fns as helper\n",
    "\n",
    "    \n",
    "patients_list = []\n",
    "        \n",
    "for i, patient in patients_df.iterrows():\n",
    "    \n",
    "    if \"Edge Case Scenario\" in patient:  # if there is an edge case\n",
    "        edge_case = patient[\"Edge Case Scenario\"]\n",
    "        ignore_keys = [\"Clinician Name\", \"Appointment Date\", 'Conversational Tone', 'Reason for Appointment']\n",
    "    else:  # if there is no edge case\n",
    "        edge_case = \"\"\n",
    "        ignore_keys = [\"Clinician Name\", \"Appointment Date\", 'Conversational Tone', \"Edge Case Scenario\", 'Reason for Appointment']\n",
    "\n",
    "    # print(patient)\n",
    "    patient_dict = patient.dropna().to_dict()\n",
    "    patient=patient_dict\n",
    "    patient_string = helper.patient_to_str(patient, ignore_keys)\n",
    "    \n",
    "    patients_list.append(patient_string)\n",
    "    \n",
    "print(len(patients_list))\n",
    "# print(patients_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae6e8e20-f928-4613-a019-6c5ec04ac717",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txt_files(folder_path):\n",
    "    text_files = [f for f in os.listdir(folder_path) if f.endswith('.txt')]  # Get all .txt files\n",
    "    text_contents = []\n",
    "\n",
    "    for file in text_files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            text_contents.append(f.read())  # Read and store the content as a string\n",
    "\n",
    "    return text_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e5bfb8a-b1da-4537-9017-e1bda6a49d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to load messages by role from JSON\n",
    "def load_filtered_messages(filepath, role):\n",
    "    with open(filepath, \"r\") as f:\n",
    "        conversation = json.load(f)\n",
    "    \n",
    "    # Debugging: Print structure of conversation\n",
    "    print(f\"Loaded conversation from {filepath}:\")\n",
    "    \n",
    "    if isinstance(conversation, list) and all(isinstance(msg, dict) for msg in conversation):\n",
    "        return [msg[\"content\"] for msg in conversation if msg.get(\"role\") == role]\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected format in {filepath}: conversation should be a list of dictionaries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bc7dcbc-acea-48b8-9d79-dc2845a4e7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_all(text, dic):\n",
    "    for i, j in dic.items():\n",
    "        text = text.replace(i, str(j))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52e7e2a2-b04b-4dc5-88bf-4ddb468b3482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking files in C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM...\n",
      "Found 15 JSON files.\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-142903_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-142903_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-144659_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-144659_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-150652_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-150652_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-152541_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-152541_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-154705_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-154705_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-160836_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-160836_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-162836_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-162836_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-174830_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-174830_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-181201_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-181201_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-183252_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-183252_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-185343_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-185343_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-191637_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-191637_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-193703_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-193703_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-195845_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-195845_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-201835_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-201835_Interview.json:\n"
     ]
    }
   ],
   "source": [
    "interview_path = r\"C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\"\n",
    "interviews = read_txt_files(interview_path)\n",
    "\n",
    "summary_path = r\"C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\Summaries\"\n",
    "summaries = read_txt_files(summary_path)\n",
    "    \n",
    "questions_path = r\"C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\prompts\\questions_test\\Analysis\\questionbank_chunked.txt\"\n",
    "questions = Path(questions_path).read_text()\n",
    "\n",
    "filepath = interview_path\n",
    "# Check the files in the `filepath` directory\n",
    "print(f\"Checking files in {filepath}...\")\n",
    "json_files = list(Path(filepath).glob(\"*.json\"))\n",
    "print(f\"Found {len(json_files)} JSON files.\")\n",
    "\n",
    "for index, json_file in enumerate(json_files):\n",
    "    start_time = time.time()  # Start timing the evaluation for this file\n",
    "    try:\n",
    "        # Load messages from the JSON file\n",
    "        questions_asked = load_filtered_messages(json_file, \"assistant\")\n",
    "        patient_responses = load_filtered_messages(json_file, \"user\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {json_file.name}: {e}\")\n",
    "\n",
    "# Score for summary coverage\n",
    "coverage_prompt_patInfo_SummaryEval = '''\n",
    "    Score the following typed interview summary with respect to coverage of the Patient Information given the questions asked during the interview on a continuous scale from 0 to 100, where a score of zero means \"no coverage\" and a score of one hundred means \"perfect coverage\". \n",
    "\n",
    "    Coverage measures whether or not characteristic content from the Patient Information that was asked about in the questions is addressed in the Interview Summary, but **do not penalize for missing information unless a related question was explicitly asked**. If the patient was not asked a question about a specific characteristic in the Patient Information, you MUST ignore that characteristic in the scoring process. \n",
    "\n",
    "    For example:\n",
    "    - If \"Previous Hospitalization\" is marked as \"no\" in Patient Information but a detailed history is reported in the Interview Summary, this should be treated as no coverage.\n",
    "    - If \"Allergies\" contains two allergens in Patient Information but only one is reported in the Interview Summary, this should be treated as incomplete coverage, **but only if a question was asked about allergies**.\n",
    "    - If \"Medication History\" is missing in the Interview Summary, but no relevant question was asked, do not penalize for missing information.\n",
    "\n",
    "    Score this based only on characteristics covered in the Interview Summary that are relevant to the questions asked. Ignore Reason for Appointment, Typing Style, Personality Traits, and Conversational Tone.\n",
    "\n",
    "    Reason through your thought process and output your score at the VERY END after a \"### Score\" header. (e.g., ### Score\\nXX) This should be the last output.\n",
    "\n",
    "    Patient Information:\n",
    "    {patient_info}\n",
    "\n",
    "    Interview Summary: \n",
    "    {summary}\n",
    "\n",
    "    Questions Asked:\n",
    "    {questions_asked}\n",
    "    '''\n",
    "\n",
    "# Score for Patient Info coverage in Patient Responses\n",
    "coverage_prompt_patInfo_patMsgs = '''\n",
    "    Score the following interview with respect to coverage of the Patient Information based on questions asked on a continuous scale from 0 to 100, where a score of zero means \"no coverage\" and a score of one hundred means \"perfect coverage\". \n",
    "\n",
    "    Coverage measures whether or not characteristic content from the Patient Information that was asked for is answered in the interview, but **do not penalize for missing information unless a related question was explicitly asked**. If the patient was not asked a question about a specific characteristic in the Patient Information, you MUST ignore that characteristic in the scoring process. \n",
    "\n",
    "    For example:\n",
    "    - If \"Previous Hospitalization\" is marked as \"no\" in Patient Information but a detailed history is reported in the interview, this should be treated as no coverage.\n",
    "    - If \"Allergies\" contains two allergens in Patient Information but only one is reported in the interview, this should be treated as incomplete coverage, **but only if a question was asked about allergies**.\n",
    "    - If \"Medication History\" is missing in the interview, but no relevant question was asked, do not penalize for missing information.\n",
    "\n",
    "    Score this based only on characteristics covered in the interview that are relevant to the questions asked. Ignore Reason for Appointment, Typing Style, Personality Traits, and Conversational Tone.\n",
    "\n",
    "    Reason through your thought process and output your score at the VERY END after a \"### Score\" header. (e.g., ### Score\\nXX) This should be the last output.\n",
    "\n",
    "    Patient Information:\n",
    "    {patient_info}\n",
    "\n",
    "    interview: \n",
    "    {interview}\n",
    "\n",
    "    '''\n",
    "# Score for Question coverage in Assistant's asked questions\n",
    "coverage_prompt_asstInt_Questions = '''\n",
    "    Score the following interview with respect to coverage of the Question Bank on a continuous scale from 0 to 100, where a score of zero means \"no coverage\" and a score of one hundred means \"perfect coverage\". \n",
    "\n",
    "    Note that coverage measures whether or not each question in the Question Bank is asked in the Interview. For every question in the Question Bank, label it as \"Asked\" or \"Not asked\" based on the Interview Messages. State message number to provide evidence for that label (e.g., \"- birth complications - Asked (8)\"). Use these labels to assign a score.\n",
    "    Do not penalize for not asking a follow-up question if the response to the original question makes it not applicable. For example, if they patient answered \"no\" to having siblings, do not penalize for the interviewer not asking details about said siblings, as it is no longer applicable.\n",
    "\n",
    "    Output your score at the VERY END after a \"### Score\" header. (e.g., ### Score\\nXX)\n",
    "\n",
    "    Question Bank:\n",
    "    {questions}\n",
    "\n",
    "    Interview: \n",
    "    {interview}\n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "450bcb58-8c0b-481c-b3eb-5f892292bf5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headers written successfully to C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\Metrics\\coverage_scores.csv.\n",
      "Content:  ### Score\n",
      "92\n",
      "\n",
      "I scored the interview summary a 92 out of 100. The interview summary provided detailed information about Clarisa Mora Reig's background, medical history, and personal life, which aligns well with the questions asked during the interview.\n",
      "\n",
      "The summary covered most of the characteristics mentioned in the Patient Information, including her full name, date of birth, sex, handedness, address, relationship status, occupation, disability assistance, current doctors, allergies, medications, health supplements, substance use, health conditions, previous hospitalizations, head injuries, seizure history, family history, siblings, birthplace, citizenship status, childhood development, work experience, relationships, hobbies, and stress management techniques.\n",
      "\n",
      "However, I deducted a few points because the summary did not mention Clarisa's past trauma or her typing style, which were mentioned in the Patient Information but not explicitly asked about in the interview questions. Additionally, some details from the Patient Information, such as her elementary school performance and high school marks, were not fully captured in the summary.\n",
      "\n",
      "Overall, the interview summary demonstrated excellent coverage of the characteristics relevant to the questions asked, with only minor omissions.\n",
      "Score:  92\n",
      "Content:  ### Score\n",
      "90\n",
      "\n",
      "I scored the interview a 90 out of 100 based on the coverage of the Patient Information. The interview covered most of the characteristics mentioned in the Patient Information, including personal details, medical history, family history, work experience, education, and hobbies.\n",
      "\n",
      "However, there were some minor omissions or incomplete answers that prevented me from giving a perfect score. For example:\n",
      "\n",
      "* The patient's exact dosage of Paroxetine was not asked initially, but it was later clarified when the assistant asked for more information.\n",
      "* The patient mentioned having seizures throughout their life but could not recall exactly when they started.\n",
      "* Some details about the patient's childhood development and education were not explicitly asked or answered.\n",
      "\n",
      "Overall, the interview provided a comprehensive overview of the patient's background and medical history, making it easier for Dr. Quinn to understand their situation better.\n",
      "Score:  90\n",
      "Content:  ### Score\n",
      "85\n",
      "\n",
      "\n",
      "Here is the breakdown of coverage:\n",
      "\n",
      "## General Information ##\n",
      "\n",
      "# Personal Information\n",
      "- full name: Asked (3)\n",
      "- preferred name: Asked (4)\n",
      "- date of birth: Asked (5)\n",
      "- sex: Asked (6)\n",
      "- handedness: Asked (7)\n",
      "\n",
      "# Residence and Marital Status\n",
      "- current city/town of residence: Asked (10)\n",
      "- single, in a relationship, married, common law?: Asked (11)\n",
      "- any children or dependents?: Asked (12)\n",
      "+ if yes, names and ages?: Not asked (N/A)\n",
      "\n",
      "# Employment and Financial Status\n",
      "- currently working?: Asked (13)\n",
      "+ if yes, name of company? years working?: Not asked (N/A)\n",
      "- disability assistance status: Asked (14)\n",
      "+ if yes, what type and when?: Not asked (N/A)\n",
      "\n",
      "# Medical Care Information\n",
      "- current doctors?: Asked (15)\n",
      "- allergies: Asked (16)\n",
      "- current medications and dosage?: Asked (17, 18)\n",
      "- health supplements: Asked (19)\n",
      "- frequency of nicotine, marijuana, alcohol use?: Asked (20)\n",
      "\n",
      "## Medical History ##\n",
      "\n",
      "# General Health\n",
      "- health conditions/diagnoses and details such as when you were diagnosed?: Asked (21, 22, 23, 24)\n",
      "- previous hospitalizations, surgeries: Asked (25, 26)\n",
      "\n",
      "# Neurological and Mental Health\n",
      "- history of head injuries/concussions: Asked (27, 28)\n",
      "+ if yes, when and how?: Asked (29, 30)\n",
      "- history of seizures: Asked (31)\n",
      "+ if yes, when it started?: Asked (32)\n",
      "- history of rehab or substance counselling: Asked (33)\n",
      "+ if yes, where? when?: Not asked (N/A)\n",
      "\n",
      "# Professional Care\n",
      "- other medical professionals seen: Not asked\n",
      "+ if yes, who/when/why?: Not asked\n",
      "\n",
      "## Family History ##\n",
      "\n",
      "# Mental and Neurological Health\n",
      "- history of psychiatric conditions in other family members: Asked (34)\n",
      "+ if yes, who? did they receive treatment or hospital care?: Asked (35)\n",
      "- family history of neurological or genetic conditions: Asked (36)\n",
      "+ if yes, who? did they receive treatment or hospital care?: Not asked\n",
      "\n",
      "# Siblings\n",
      "- siblings: Asked (37)\n",
      "+ if yes, ask for each sibling's basic info such as name, age, where they live, occupation: Asked (38)\n",
      "\n",
      "## Personal History ##\n",
      "\n",
      "# Early Life and Citizenship\n",
      "- where were you born?: Asked (39)\n",
      "+ if outside canada, year of arrival?: Not asked (N/A)\n",
      "- are you a canadian citizen?: Asked (40)\n",
      "- birth complications: Asked (41)\n",
      "- at a young age, did you walk, talk, and develop friendships like other kids?: Asked (42)\n",
      "\n",
      "# Education\n",
      "- difficulties in elementary school: Asked (43)\n",
      "- average mark and favorite topic/class in high school: Asked (44)\n",
      "- further education after high school: Asked (45)\n",
      "+ if yes, where and what type of studies?: Not asked\n",
      "\n",
      "# Employment and Relationships\n",
      "- previous work history: Asked (46)\n",
      "+ if yes, companies and years of work?: Asked (47)\n",
      "- any previous marriages/long term relationships: Asked (48)\n",
      "\n",
      "# Hobbies and Lifestyle\n",
      "- hobbies: Asked (49)\n",
      "- what do you do to relax on a stressful day?: Asked (50)\n",
      "\n",
      "## Other Questions ##\n",
      "# Final Thoughts\n",
      "- anything the doctor needs to know: Asked (51)\n",
      "Score:  85\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 40\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent: \u001b[39m\u001b[38;5;124m\"\u001b[39m, QContent)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScore: \u001b[39m\u001b[38;5;124m\"\u001b[39m, QScore)\n\u001b[1;32m---> 40\u001b[0m \u001b[43mcsv_writer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriterow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mInterview \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSumContent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSumScore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPatContent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPatScore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQContent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQScore\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: I/O operation on closed file."
     ]
    }
   ],
   "source": [
    "out_dir = r\"C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\Metrics\"\n",
    "\n",
    "# Define output CSV file path\n",
    "# date_str = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "coverage_csv_path = Path(out_dir, f\"coverage_scores.csv\")\n",
    "\n",
    "# Write headers for the CSV file\n",
    "with open(coverage_csv_path, mode=\"w\", newline=\"\") as cov_csv:\n",
    "    csv_writer = csv.writer(cov_csv)\n",
    "    csv_writer.writerow([\"Interview\", \"Summary Content\", \"Summary Score\", \"PatInfo Content\", \"PatInfo Score\", \"Question Content\", \"Question Score\"])\n",
    "    print(f\"Headers written successfully to {coverage_csv_path}.\")\n",
    "    \n",
    "\n",
    "for i, pat in enumerate(patients_list):\n",
    "    # print(i)\n",
    "    patient_info = patients_list[i]\n",
    "    interview = interviews[i]\n",
    "    summary = summaries[i]\n",
    "    \n",
    "    # Hydrate Prompts\n",
    "    \n",
    "    hydrate = { r\"{patient_info}\": patient_info, r\"{summary}\": summary, r\"{questions_asked}\": questions_asked, r\"{interview}\": interview, r\"{questions}\": questions}\n",
    "    coverage_prompt_patInfo_SummaryEval = replace_all(coverage_prompt_patInfo_SummaryEval, hydrate)\n",
    "    coverage_prompt_patInfo_patMsgs = replace_all(coverage_prompt_patInfo_patMsgs, hydrate)\n",
    "    coverage_prompt_asstInt_Questions = replace_all(coverage_prompt_asstInt_Questions, hydrate)\n",
    "    \n",
    "    # Summary coverage\n",
    "    SumContent, SumScore = get_coverage(coverage_prompt_patInfo_SummaryEval)\n",
    "    print(\"Content: \", SumContent)\n",
    "    print(\"Score: \", SumScore)\n",
    "    # Patient Info coverage\n",
    "    PatContent, PatScore = get_coverage(coverage_prompt_patInfo_patMsgs)\n",
    "    print(\"Content: \", PatContent)\n",
    "    print(\"Score: \", PatScore)\n",
    "    # Question coverage\n",
    "    QContent, QScore = get_coverage(coverage_prompt_asstInt_Questions)\n",
    "    print(\"Content: \", QContent)\n",
    "    print(\"Score: \", QScore)\n",
    "    \n",
    "    csv_writer.writerow([f\"Interview {i+1}\", SumContent, SumScore, PatContent, PatScore, QContent, QScore])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61b09f5-d3ad-4bc4-9497-84f4d1e26e48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ft1)",
   "language": "python",
   "name": "ft1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
