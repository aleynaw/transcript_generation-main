{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cb24ccb-fe1b-4d15-b5d7-e668d26be979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import random\n",
    "import time\n",
    "\n",
    "from openai import OpenAI\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42944d82-bf45-4d0f-a599-bf79629e0dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Langchain and Ollama\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "model1 = OllamaLLM(base_url=\"localhost:11435\", \n",
    "                  model=\"llama3.1:70b-instruct-q4_0\", \n",
    "                  temperature=0.5, \n",
    "                  num_ctx = 6144,\n",
    "                  top_k = 40,\n",
    "                  top_p = 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ece24d2b-6630-4fd2-8647-322efb54e80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llama_response(messages_list):\n",
    "    '''obtain response from llama'''\n",
    "\n",
    "    response = model1.invoke(messages_list)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74e88cad-9dc2-4555-8a22-d5ad40052e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coverage(coverage_prompt):\n",
    "    \n",
    "    # Call the local LLaMA model instead of OpenAI's API\n",
    "    content = get_llama_response(coverage_prompt)\n",
    "    \n",
    "    try:\n",
    "        specificity_val = int(content.split(\"### Score\")[-1][:4].strip())\n",
    "    except ValueError:\n",
    "        specificity_val = np.NaN\n",
    "    \n",
    "    return content, specificity_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "091f6410-daad-4d1a-88eb-c2097e649800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent Directory: C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "import sys, os, csv, ast, random, time, re, json\n",
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "patients_path = Path(r\"C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\patient_creation\\llm_patients.csv\")\n",
    "patients_df = pd.read_csv(patients_path,delimiter=\"|\")\n",
    "# print(patients_df)\n",
    "\n",
    "parent_directory = Path.cwd().resolve().parent.parent.parent.parent\n",
    "print(f\"Parent Directory: {parent_directory}\")\n",
    "\n",
    "sys.path.append(str(parent_directory))\n",
    "\n",
    "try:\n",
    "    sys.path.append('../../transcript_generation')\n",
    "    from transcript_generation import helper_fns as helper\n",
    "except ModuleNotFoundError:\n",
    "    import helper_fns as helper\n",
    "\n",
    "    \n",
    "patients_list = []\n",
    "        \n",
    "for i, patient in patients_df.iterrows():\n",
    "    \n",
    "    if \"Edge Case Scenario\" in patient:  # if there is an edge case\n",
    "        edge_case = patient[\"Edge Case Scenario\"]\n",
    "        ignore_keys = [\"Clinician Name\", \"Appointment Date\", 'Conversational Tone', 'Reason for Appointment']\n",
    "    else:  # if there is no edge case\n",
    "        edge_case = \"\"\n",
    "        ignore_keys = [\"Clinician Name\", \"Appointment Date\", 'Conversational Tone', \"Edge Case Scenario\", 'Reason for Appointment']\n",
    "\n",
    "    # print(patient)\n",
    "    patient_dict = patient.dropna().to_dict()\n",
    "    patient=patient_dict\n",
    "    patient_string = helper.patient_to_str(patient, ignore_keys)\n",
    "    \n",
    "    patients_list.append(patient_string)\n",
    "    \n",
    "print(len(patients_list))\n",
    "# print(patients_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae6e8e20-f928-4613-a019-6c5ec04ac717",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txt_files(folder_path):\n",
    "    text_files = [f for f in os.listdir(folder_path) if f.endswith('.txt')]  # Get all .txt files\n",
    "    text_contents = []\n",
    "\n",
    "    for file in text_files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            text_contents.append(f.read())  # Read and store the content as a string\n",
    "\n",
    "    return text_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e5bfb8a-b1da-4537-9017-e1bda6a49d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to load messages by role from JSON\n",
    "def load_filtered_messages(filepath, role):\n",
    "    with open(filepath, \"r\") as f:\n",
    "        conversation = json.load(f)\n",
    "    \n",
    "    # Debugging: Print structure of conversation\n",
    "    print(f\"Loaded conversation from {filepath}:\")\n",
    "    \n",
    "    if isinstance(conversation, list) and all(isinstance(msg, dict) for msg in conversation):\n",
    "        return [msg[\"content\"] for msg in conversation if msg.get(\"role\") == role]\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected format in {filepath}: conversation should be a list of dictionaries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bc7dcbc-acea-48b8-9d79-dc2845a4e7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_all(text, dic):\n",
    "    for i, j in dic.items():\n",
    "        text = text.replace(i, str(j))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52e7e2a2-b04b-4dc5-88bf-4ddb468b3482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking files in C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM...\n",
      "Found 15 JSON files.\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-142903_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-142903_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-144659_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-144659_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-150652_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-150652_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-152541_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-152541_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-154705_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-154705_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-160836_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-160836_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-162836_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-162836_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-174830_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-174830_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-181201_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-181201_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-183252_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-183252_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-185343_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-185343_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-191637_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-191637_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-193703_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-193703_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-195845_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-195845_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-201835_Interview.json:\n",
      "Loaded conversation from C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\\DM_20241112-201835_Interview.json:\n"
     ]
    }
   ],
   "source": [
    "interview_path = r\"C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\DM\"\n",
    "interviews = read_txt_files(interview_path)\n",
    "\n",
    "summary_path = r\"C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\Summaries\"\n",
    "summaries = read_txt_files(summary_path)\n",
    "    \n",
    "questions_path = r\"C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\prompts\\questions_test\\Analysis\\questionbank_chunked.txt\"\n",
    "questions = Path(questions_path).read_text()\n",
    "\n",
    "filepath = interview_path\n",
    "# Check the files in the `filepath` directory\n",
    "print(f\"Checking files in {filepath}...\")\n",
    "json_files = list(Path(filepath).glob(\"*.json\"))\n",
    "print(f\"Found {len(json_files)} JSON files.\")\n",
    "\n",
    "for index, json_file in enumerate(json_files):\n",
    "    start_time = time.time()  # Start timing the evaluation for this file\n",
    "    try:\n",
    "        # Load messages from the JSON file\n",
    "        questions_asked = load_filtered_messages(json_file, \"assistant\")\n",
    "        patient_responses = load_filtered_messages(json_file, \"user\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {json_file.name}: {e}\")\n",
    "\n",
    "# Score for summary coverage\n",
    "coverage_prompt_patInfo_SummaryEval = '''\n",
    "    Score the following typed interview summary with respect to coverage of the Patient Information given the questions asked during the interview on a continuous scale from 0 to 100, where a score of zero means \"no coverage\" and a score of one hundred means \"perfect coverage\". \n",
    "\n",
    "    Coverage measures whether or not characteristic content from the Patient Information that was asked about in the questions is addressed in the Interview Summary, but **do not penalize for missing information unless a related question was explicitly asked**. If the patient was not asked a question about a specific characteristic in the Patient Information, you MUST ignore that characteristic in the scoring process. \n",
    "\n",
    "    For example:\n",
    "    - If \"Previous Hospitalization\" is marked as \"no\" in Patient Information but a detailed history is reported in the Interview Summary, this should be treated as no coverage.\n",
    "    - If \"Allergies\" contains two allergens in Patient Information but only one is reported in the Interview Summary, this should be treated as incomplete coverage, **but only if a question was asked about allergies**.\n",
    "    - If \"Medication History\" is missing in the Interview Summary, but no relevant question was asked, do not penalize for missing information.\n",
    "\n",
    "    Score this based only on characteristics covered in the Interview Summary that are relevant to the questions asked. Ignore Reason for Appointment, Typing Style, Personality Traits, and Conversational Tone.\n",
    "\n",
    "    Reason through your thought process and output your score at the VERY END after a \"### Score\" header. (e.g., ### Score\\nXX) This should be the last output.\n",
    "\n",
    "    Patient Information:\n",
    "    {patient_info}\n",
    "\n",
    "    Interview Summary: \n",
    "    {summary}\n",
    "\n",
    "    Questions Asked:\n",
    "    {questions_asked}\n",
    "    '''\n",
    "\n",
    "# Score for Patient Info coverage in Patient Responses\n",
    "coverage_prompt_patInfo_patMsgs = '''\n",
    "    Score the following interview with respect to coverage of the Patient Information based on questions asked on a continuous scale from 0 to 100, where a score of zero means \"no coverage\" and a score of one hundred means \"perfect coverage\". \n",
    "\n",
    "    Coverage measures whether or not characteristic content from the Patient Information that was asked for is answered in the interview, but **do not penalize for missing information unless a related question was explicitly asked**. If the patient was not asked a question about a specific characteristic in the Patient Information, you MUST ignore that characteristic in the scoring process. \n",
    "\n",
    "    For example:\n",
    "    - If \"Previous Hospitalization\" is marked as \"no\" in Patient Information but a detailed history is reported in the interview, this should be treated as no coverage.\n",
    "    - If \"Allergies\" contains two allergens in Patient Information but only one is reported in the interview, this should be treated as incomplete coverage, **but only if a question was asked about allergies**.\n",
    "    - If \"Medication History\" is missing in the interview, but no relevant question was asked, do not penalize for missing information.\n",
    "\n",
    "    Score this based only on characteristics covered in the interview that are relevant to the questions asked. Ignore Reason for Appointment, Typing Style, Personality Traits, and Conversational Tone.\n",
    "\n",
    "    Reason through your thought process and output your score at the VERY END after a \"### Score\" header. (e.g., ### Score\\nXX) This should be the last output.\n",
    "\n",
    "    Patient Information:\n",
    "    {patient_info}\n",
    "\n",
    "    interview: \n",
    "    {interview}\n",
    "\n",
    "    '''\n",
    "# Score for Question coverage in Assistant's asked questions\n",
    "coverage_prompt_asstInt_Questions = '''\n",
    "    Score the following interview with respect to coverage of the Question Bank on a continuous scale from 0 to 100, where a score of zero means \"no coverage\" and a score of one hundred means \"perfect coverage\". \n",
    "\n",
    "    Note that coverage measures whether or not each question in the Question Bank is asked in the Interview. For every question in the Question Bank, label it as \"Asked\" or \"Not asked\" based on the Interview Messages. State message number to provide evidence for that label (e.g., \"- birth complications - Asked (8)\"). Use these labels to assign a score.\n",
    "    Do not penalize for not asking a follow-up question if the response to the original question makes it not applicable. For example, if they patient answered \"no\" to having siblings, do not penalize for the interviewer not asking details about said siblings, as it is no longer applicable.\n",
    "\n",
    "    Output your score at the VERY END after a \"### Score\" header. (e.g., ### Score\\nXX)\n",
    "\n",
    "    Question Bank:\n",
    "    {questions}\n",
    "\n",
    "    Interview: \n",
    "    {interview}\n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "450bcb58-8c0b-481c-b3eb-5f892292bf5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headers written successfully to C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\Metrics\\coverage_scores.csv.\n",
      "Content:  ### Score\n",
      "\n",
      "I would score this interview summary an 82 out of 100 in terms of coverage of both the Patient Information and the questions asked during the interview.\n",
      "\n",
      "The interview summary covers most of the important characteristics from the Patient Information, including full name, preferred name, date of birth, sex, handedness, current city/town of residence, marital status, employment status, disability assistance status, current doctors, allergies, current medication use, health supplements, frequency of substance use, health conditions/diagnoses, previous hospitalizations/surgeries, head injury history, seizure history, family history of psychiatric conditions, birthplace, citizenship status, childhood development, work history, relationship history, hobbies, and stress management techniques.\n",
      "\n",
      "However, there are a few areas where the coverage is incomplete or missing. For example:\n",
      "\n",
      "* The interview summary does not mention the patient's occupation as \"unemployed\", which is listed in the Patient Information.\n",
      "* The interview summary does not provide detailed information about the patient's previous work experience, such as job titles and company names, which are listed in the Patient Information.\n",
      "* The interview summary does not mention the patient's personality traits, such as \"Kind\", \"Confident\", and \"Open-minded\", which are listed in the Patient Information.\n",
      "\n",
      "Additionally, some of the questions asked during the interview do not seem to be directly related to the characteristics listed in the Patient Information. For example, the question about the patient's comfort level with sharing background information does not appear to be relevant to any specific characteristic in the Patient Information.\n",
      "\n",
      "Overall, while the interview summary covers most of the important characteristics from the Patient Information, there are some areas where the coverage is incomplete or missing.\n",
      "Score:  nan\n",
      "Content:  ### Score\n",
      "\n",
      "I would score the interview a 98 out of 100 in terms of coverage of both the Patient Information and the questions asked during the interview.\n",
      "\n",
      "The interview covers almost all the relevant characteristics from the Patient Information, including personal details (name, date of birth, sex, handedness), contact information (address), relationship status, employment status, disability assistance, current doctors, allergies, medications, health conditions, previous hospitalizations or surgeries, head injuries or concussions, family history, and more.\n",
      "\n",
      "The interview also asks relevant follow-up questions to gather more information about the patient's condition, such as dosage of medication, frequency of substance use, and relaxation techniques. The only characteristic that is not explicitly mentioned in the interview is \"Typing Style\", but this is excluded from scoring according to the instructions.\n",
      "\n",
      "The only reason I wouldn't give a perfect score of 100 is that there are some minor inconsistencies or lack of detail in the patient's responses (e.g., exact start time of seizures, treatment received by family members), and some questions could have been asked more explicitly or followed up on for further clarification. However, overall, the interview does an excellent job of gathering comprehensive information about the patient's background and condition.\n",
      "Score:  nan\n",
      "Content:  ### Score\n",
      "92\n",
      "\n",
      "Note:\n",
      "\n",
      "* Questions about siblings' basic info (name, age, where they live, occupation) were not asked.\n",
      "* Questions about family history of neurological or genetic conditions did not ask for treatment or hospital care details.\n",
      "* Some questions had follow-up questions that were not explicitly listed in the Question Bank but provided additional information.\n",
      "Score:  92\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 40\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent: \u001b[39m\u001b[38;5;124m\"\u001b[39m, QContent)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScore: \u001b[39m\u001b[38;5;124m\"\u001b[39m, QScore)\n\u001b[1;32m---> 40\u001b[0m \u001b[43mcsv_writer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriterow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mInterview \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSumContent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSumScore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPatContent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPatScore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQContent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQScore\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: I/O operation on closed file."
     ]
    }
   ],
   "source": [
    "out_dir = r\"C:\\Users\\aleynaw\\Desktop\\transcript_generation-main\\transcript_generation\\transcripts\\llama3.1\\Metrics\"\n",
    "\n",
    "# Define output CSV file path\n",
    "# date_str = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "coverage_csv_path = Path(out_dir, f\"coverage_scores.csv\")\n",
    "\n",
    "# Write headers for the CSV file\n",
    "with open(coverage_csv_path, mode=\"w\", newline=\"\") as cov_csv:\n",
    "    csv_writer = csv.writer(cov_csv)\n",
    "    csv_writer.writerow([\"Interview\", \"Summary Content\", \"Summary Score\", \"PatInfo Content\", \"PatInfo Score\", \"Question Content\", \"Question Score\"])\n",
    "    print(f\"Headers written successfully to {coverage_csv_path}.\")\n",
    "    \n",
    "\n",
    "for i, pat in enumerate(patients_list):\n",
    "    # print(i)\n",
    "    patient_info = patients_list[i]\n",
    "    interview = interviews[i]\n",
    "    summary = summaries[i]\n",
    "    \n",
    "    # Hydrate Prompts\n",
    "    \n",
    "    hydrate = { r\"{patient_info}\": patient_info, r\"{summary}\": summary, r\"{questions_asked}\": questions_asked, r\"{interview}\": interview, r\"{questions}\": questions}\n",
    "    coverage_prompt_patInfo_SummaryEval = replace_all(coverage_prompt_patInfo_SummaryEval, hydrate)\n",
    "    coverage_prompt_patInfo_patMsgs = replace_all(coverage_prompt_patInfo_patMsgs, hydrate)\n",
    "    coverage_prompt_asstInt_Questions = replace_all(coverage_prompt_asstInt_Questions, hydrate)\n",
    "    \n",
    "    # Summary coverage\n",
    "    SumContent, SumScore = get_coverage(coverage_prompt_patInfo_SummaryEval)\n",
    "    print(\"Content: \", SumContent)\n",
    "    print(\"Score: \", SumScore)\n",
    "    # Patient Info coverage\n",
    "    PatContent, PatScore = get_coverage(coverage_prompt_patInfo_patMsgs)\n",
    "    print(\"Content: \", PatContent)\n",
    "    print(\"Score: \", PatScore)\n",
    "    # Question coverage\n",
    "    QContent, QScore = get_coverage(coverage_prompt_asstInt_Questions)\n",
    "    print(\"Content: \", QContent)\n",
    "    print(\"Score: \", QScore)\n",
    "    \n",
    "    csv_writer.writerow([f\"Interview {i+1}\", SumContent, SumScore, PatContent, PatScore, QContent, QScore])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61b09f5-d3ad-4bc4-9497-84f4d1e26e48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llm)",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
