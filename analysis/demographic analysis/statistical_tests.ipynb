{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d5add52-098f-4dcf-8a51-8b47da545321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import ast\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4bebf2c-428a-481c-980f-d8076c9e9e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!! Modify this to match the name of the csv file of the patients you generated\n",
    "file_path = \"llm_patients_043025.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7390c26-2d77-41af-a12e-5531fe5ae96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Hard-coded Demographic Distributions\n",
    "# =============================================================================\n",
    "\n",
    "\"\"\" This data is the same as the demographic distributions from the llm_patient_creator.ipynb file. \"\"\"\n",
    "# split distributions to a .py file?\n",
    "\n",
    "# Age distribution (averaged for men & women).\n",
    "AGE_WEIGHTS_MEN = np.array([0.2979, 0.1916, 0.1557, 0.2266, 0.1282])\n",
    "AGE_WEIGHTS_WOMEN = np.array([0.2861, 0.1683, 0.1483, 0.2343, 0.1630])\n",
    "\n",
    "# Relationship status percentages by age group: (18-25, 26-35, 36-45, 46-60, 60+)\n",
    "RELATIONSHIP_STATUS_DISTRIBUTIONS = [ # Single, Long-term relationship, Married/Common-Law, Divorced/Separated, Widowded\n",
    "    [69.26, 23.09,  7.40,  0.25,  0.00],  # 18-25\n",
    "    [31.73, 10.58, 55.35,  2.15,  0.20],  # 26-35\n",
    "    [10.88,  3.63, 76.00,  8.15,  1.35],  # 36-45\n",
    "    [ 9.00,  3.00, 68.33, 15.33,  8.17],  # 46-60\n",
    "    [11.25,  3.75, 54.17,  8.83, 33.50],  # 60+\n",
    "]\n",
    "\n",
    "# Probabilities of being \"in a family\" & \"with children,\" by 4 age bins (0-24, 25-34, 35-44, 45-54).\n",
    "IN_FAMILY = [\n",
    "    [0.0756, 0.0701],  # female, male (0-24)\n",
    "    [0.5102, 0.4765],  # female, male (25-34)\n",
    "    [0.8340, 0.8178],  # female, male (35-44)\n",
    "    [0.8426, 0.8557],  # female, male (45+)\n",
    "]\n",
    "WITH_CHILDREN = [\n",
    "    [0.6997, 0.3003],  # yes, no  (0-24)\n",
    "    [0.5193, 0.4807],  # yes, no  (25-34)\n",
    "    [0.2056, 0.7944],  # yes, no  (35-44)\n",
    "    [0.1771, 0.8229],  # yes, no  (45+)\n",
    "]\n",
    "\n",
    "SEX_WEIGHTS = [0.51, 0.49]\n",
    "SEX_LABELS = [\"Male\", \"Female\"]\n",
    "\n",
    "AGE_ORDER = [\"18-25\", \"26-35\", \"36-45\", \"46-60\", \"60+\"]\n",
    "\n",
    "RELATIONSHIP_ORDER = [\"Single\", \"Long-term relationship\",\n",
    "                          \"Married/Common-Law\", \"Divorced/Separated\", \"Widowded\"]\n",
    "\n",
    "\n",
    "DISABILITY_CATEGORIES = [\n",
    "        \"Mental-health related\", \"Pain-related\", \"Seeing\",\n",
    "        \"Learning\", \"Memory\", \"Mobility\", \"Flexibility\",\n",
    "        \"Hearing\", \"Dexterity\", \"Developmental\"\n",
    "    ]\n",
    "\n",
    "ETHNICITY_PROBABILITY = [0.0243, 0.0334, 0.4313, 0.2328, 0.1417, 0.0763, 0.0198, 0.0158, 0.0251]\n",
    "\n",
    "ETHNICITY_ORDER = [\"Indigenous\", \"Middle Eastern\", \"European\", \n",
    "                   \"East Asian\", \"South Asian\", \"Southeast Asian\", \n",
    "                   \"Latin American\", \"African\", \"Other\"]\n",
    "\n",
    "ETHNICITY_CATEGORIES = {\n",
    "    \"Indigenous\": [\n",
    "        \"Indigenous\"\n",
    "    ],\n",
    "    \"Middle Eastern\": [\"Persian - Iran\", \"Hebrew - Israel\"],\n",
    "    \"European\": [\n",
    "        \"Czech - Czech Republic\", \"Danish - Denmark\", \"German - Austria\", \"German - Switzerland\", \"German - Germany\",\n",
    "        \"Greek - Greece\", \"English - Canada\", \"English - United States\", \"English - United Kingdom\", \"English - Ireland\",\n",
    "        \"Spanish - Spain\", \"Finnish - Finland\", \"French - Canada\", \"French - Switzerland\", \"French - France\",\n",
    "        \"Croatian - Croatia\", \"Hungarian - Hungary\", \"Armenian - Armenia\", \"Italian - Italy\", \"Dutch - Belgium\",\n",
    "        \"Dutch - Netherlands\", \"Norwegian - Norway\", \"Polish - Poland\", \"Portuguese - Portugal\", \"Romanian - Romania\",\n",
    "        \"Russian - Russia\", \"Slovak - Slovakia\", \"Swedish - Sweden\", \"Ukrainian - Ukraine\"\n",
    "    ],\n",
    "    \"East Asian\": [\n",
    "        \"Japanese - Japan\", \"Korean - South Korea\",\n",
    "        \"Chinese - China\", \"Chinese - Taiwan\"\n",
    "    ],\n",
    "    \"South Asian\": [\n",
    "        \"English - India\", \"Hindi - India\", \"Nepali - Nepal\",\n",
    "        \"Tamil - India\", \"Bengali - Bangladesh\", \"English - Bangladesh\",\n",
    "        \"Georgian - Georgia\", \"Azerbaijani - Azerbaijan\"\n",
    "    ],\n",
    "    \"Southeast Asian\": [\n",
    "        \"English - Malaysia\", \"English - Philippines\", \"Filipino - Philippines\",\n",
    "        \"Indonesian - Indonesia\", \"Thai - Thailand\", \"Tagalog - Philippines\",\n",
    "        \"Vietnamese - Vietnam\"\n",
    "    ],\n",
    "    \"Latin American\": [\n",
    "        \"Spanish - Argentina\", \"Spanish - Chile\", \"Spanish - Colombia\",\n",
    "        \"Spanish - Mexico\", \"Portuguese - Brazil\"\n",
    "    ],\n",
    "    \"African\": [\"Zulu - South Africa\"],\n",
    "    \"Other\": [\"English - Australia\", \"English - New Zealand\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a877dc9-002a-44d4-a018-7d62e67d365e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Statistical Tests\n",
    "# =============================================================================\n",
    "\n",
    "def binomial_p_value(n, p, observed_count, tail='right'):\n",
    "    \"\"\"\n",
    "    Compute the p-value for a binomial distribution using a normal approximation.\n",
    "    \"\"\"\n",
    "    expected = n * p\n",
    "    print(\"expected:\", expected)\n",
    "    sigma = np.sqrt(n * p * (1 - p))\n",
    "    print(\"sigma:\", sigma)\n",
    "    print(\"obs:\", observed_count)\n",
    "    z_score = (observed_count - expected) / sigma\n",
    "    print(\"z:\", z_score)\n",
    "    \n",
    "    if observed_count > expected:\n",
    "        print(\"right\")\n",
    "        print(\"observed:\", observed_count)\n",
    "        print(\"expected:\", expected)\n",
    "        p_value = 1 - stats.norm.cdf(z_score)\n",
    "    else:  # left tail\n",
    "        print(\"left\")\n",
    "        p_value = stats.norm.cdf(z_score)\n",
    "    \n",
    "    return z_score, p_value\n",
    "\n",
    "def multinomial_p_value(observed_counts, expected_probs):\n",
    "    \"\"\"\n",
    "    Compute the p-value for a multinomial distribution using the chi-square test.\n",
    "    \"\"\"\n",
    "    total_n = sum(observed_counts)\n",
    "    expected_counts = np.array(expected_probs) * total_n\n",
    "    print(\"expected:\", expected_counts)\n",
    "    print(\"observed:\", observed_counts)\n",
    "    chi_square_stat, p_value = stats.chisquare(f_obs=observed_counts, f_exp=expected_counts)\n",
    "    # chi_square_stat = 0\n",
    "    # p_value = 0\n",
    "    return chi_square_stat, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b01964f-fb26-4085-92a1-16096e7cc2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Analysis and Plotting\n",
    "# =============================================================================\n",
    "\n",
    "def analyze(df, column, expected_probs, title, chart_type='bar', order=None):\n",
    "    \"\"\"\n",
    "    Perform statistical analysis for a given categorical column.\n",
    "    \"\"\"\n",
    "\n",
    "    # If an order is provided, reindex the observed counts accordingly\n",
    "    if order is not None:\n",
    "        observed_counts = df[column].value_counts().reindex(order, fill_value=0)\n",
    "    else:\n",
    "        observed_counts = df[column].value_counts().sort_index()\n",
    "        \n",
    "    print(\"counts:\", observed_counts)\n",
    "    print(type(observed_counts))\n",
    "    observed_probs = observed_counts / observed_counts.sum()\n",
    "    print(\"probs:\", observed_probs)\n",
    "    \n",
    "    # Normalize probabilities\n",
    "    expected_probs = np.array(expected_probs) / np.sum(expected_probs)\n",
    "    \n",
    "    if len(expected_probs) == 2:\n",
    "        # Binomial test\n",
    "        print(observed_counts.sum(), expected_probs[1], observed_counts.iloc[1])\n",
    "        z_score, p_value = binomial_p_value(observed_counts.sum(), expected_probs[1], observed_counts.iloc[1])\n",
    "        print(f\"{title} - Z-score: {z_score:.2f}, P-value: {p_value:.4f}\")\n",
    "    else:\n",
    "        # Multinomial test\n",
    "        chi_square_stat, p_value = multinomial_p_value(observed_counts.values, expected_probs)\n",
    "        print(f\"{title} - Chi-Square: {chi_square_stat:.2f}, P-value: {p_value:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ffcbe3c-e67a-4885-a6c7-411c083d689e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Helper Functions\n",
    "# =============================================================================\n",
    "\n",
    "def categorize_ethnicity(ethnicity):\n",
    "    for category, values in ETHNICITY_CATEGORIES.items():\n",
    "         if ethnicity in values:\n",
    "            return category\n",
    "    return \"Uncategorized\"\n",
    "\n",
    "\n",
    "def compute_expected_disability(row: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Hard-coded probability of being disabled by (sex, age),\n",
    "    then distribute among 10 disability types.\n",
    "    \"\"\"\n",
    "\n",
    "    # Hard-coded distribution across 10 types\n",
    "    s = 38.6 + 61.8 + 27.4 + 20.7 + 18.2 + 39.2 + 40.3 + 20.7 + 18.4 + 5.7\n",
    "    DISABILITY_PROBABILITY_TYPES_NORM = [\n",
    "        38.6/s, 61.8/s, 27.4/s, 20.7/s, 18.2/s,\n",
    "        39.2/s, 40.3/s, 20.7/s, 18.4/s, 5.7/s\n",
    "    ]\n",
    "    expected_values = {\n",
    "        cat: p_type\n",
    "        for cat, p_type in zip(DISABILITY_CATEGORIES, DISABILITY_PROBABILITY_TYPES_NORM)\n",
    "    }\n",
    "    return pd.Series(expected_values)\n",
    "\n",
    "def categorize_age(age):\n",
    "    \"\"\"\n",
    "    Categorize age into groups:\n",
    "    18-25, 26-35, 36-45, 46-60, 60+.\n",
    "    \"\"\"\n",
    "    if age < 18:\n",
    "        return \"Under 18\"\n",
    "    elif 18 <= age <= 25:\n",
    "        return \"18-25\"\n",
    "    elif 26 <= age <= 35:\n",
    "        return \"26-35\"\n",
    "    elif 36 <= age <= 45:\n",
    "        return \"36-45\"\n",
    "    elif 46 <= age <= 60:\n",
    "        return \"46-60\"\n",
    "    else:\n",
    "        return \"60+\"\n",
    "\n",
    "def compute_expected_age_probs(df):\n",
    "    \"\"\"\n",
    "    Compute overall expected age probabilities using provided weights and the sex distribution in df.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate proportion of males and females in the dataset\n",
    "    sex_counts = df['Sex'].value_counts(normalize=True)\n",
    "    prop_male = sex_counts.get(\"Male\", 0)\n",
    "    prop_female = sex_counts.get(\"Female\", 0)\n",
    "    \n",
    "    overall_expected = prop_male * AGE_WEIGHTS_MEN + prop_female * AGE_WEIGHTS_WOMEN\n",
    "    print(\"Expected age probabilities:\", overall_expected)\n",
    "    return overall_expected, AGE_ORDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db5a7b01-92d3-4518-aa28-7907e8ca94d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Statistical Tests and Graphs ===\n",
      "\n",
      "counts: Sex\n",
      "Female    500\n",
      "Male      500\n",
      "Name: count, dtype: int64\n",
      "<class 'pandas.core.series.Series'>\n",
      "probs: Sex\n",
      "Female    0.5\n",
      "Male      0.5\n",
      "Name: count, dtype: float64\n",
      "1000 0.49 500\n",
      "expected: 490.0\n",
      "sigma: 15.8082257068907\n",
      "obs: 500\n",
      "z: 0.6325820611000681\n",
      "right\n",
      "observed: 500\n",
      "expected: 490.0\n",
      "Sex Distribution - Z-score: 0.63, P-value: 0.2635\n",
      "Expected age probabilities: [0.292   0.17995 0.152   0.23045 0.1456 ]\n",
      "counts: Age_Category\n",
      "18-25    313\n",
      "26-35    170\n",
      "36-45    145\n",
      "46-60    230\n",
      "60+      142\n",
      "Name: count, dtype: int64\n",
      "<class 'pandas.core.series.Series'>\n",
      "probs: Age_Category\n",
      "18-25    0.313\n",
      "26-35    0.170\n",
      "36-45    0.145\n",
      "46-60    0.230\n",
      "60+      0.142\n",
      "Name: count, dtype: float64\n",
      "expected: [292.   179.95 152.   230.45 145.6 ]\n",
      "observed: [313 170 145 230 142]\n",
      "Age Distribution - Chi-Square: 2.47, P-value: 0.6495\n",
      "counts: Ethnicity_Category\n",
      "Indigenous          25\n",
      "Middle Eastern      29\n",
      "European           396\n",
      "East Asian         255\n",
      "South Asian        132\n",
      "Southeast Asian     87\n",
      "Latin American      23\n",
      "African             21\n",
      "Other               32\n",
      "Name: count, dtype: int64\n",
      "<class 'pandas.core.series.Series'>\n",
      "probs: Ethnicity_Category\n",
      "Indigenous         0.025\n",
      "Middle Eastern     0.029\n",
      "European           0.396\n",
      "East Asian         0.255\n",
      "South Asian        0.132\n",
      "Southeast Asian    0.087\n",
      "Latin American     0.023\n",
      "African            0.021\n",
      "Other              0.032\n",
      "Name: count, dtype: float64\n",
      "expected: [ 24.28785607  33.38330835 431.08445777 232.68365817 141.62918541\n",
      "  76.26186907  19.79010495  15.79210395  25.08745627]\n",
      "observed: [ 25  29 396 255 132  87  23  21  32]\n",
      "Ethnicity Distribution - Chi-Square: 11.90, P-value: 0.1556\n",
      "total obs: 564\n",
      "counts: Mental-health related    81\n",
      "Pain-related             98\n",
      "Seeing                   59\n",
      "Learning                 34\n",
      "Memory                   45\n",
      "Mobility                 78\n",
      "Flexibility              80\n",
      "Hearing                  45\n",
      "Dexterity                35\n",
      "Developmental             9\n",
      "dtype: int64\n",
      "expected: [ 74.81237113 119.77731959  53.10515464  40.11958763  35.2742268\n",
      "  75.97525773  78.10721649  40.11958763  35.66185567  11.04742268]\n",
      "observed: [81 98 59 34 45 78 80 45 35  9]\n",
      "Disability Breakdown - Chi-Square: 9.83, P-value: 0.3648\n",
      "obs:          Single  Long-term relationship  Married/Common-Law  \\\n",
      "18-25  0.680511                0.242812            0.076677   \n",
      "26-35  0.335294                0.111765            0.535294   \n",
      "36-45  0.117241                0.020690            0.800000   \n",
      "46-60  0.104348                0.026087            0.673913   \n",
      "60+    0.126761                0.035211            0.464789   \n",
      "\n",
      "       Divorced/Separated  Widowded  \n",
      "18-25            0.000000  0.000000  \n",
      "26-35            0.017647  0.000000  \n",
      "36-45            0.048276  0.013793  \n",
      "46-60            0.147826  0.047826  \n",
      "60+              0.063380  0.309859  \n",
      "exp:        Single  Long-term relationship  Married/Common-Law  Divorced/Separated  \\\n",
      "18-25  0.6926                  0.2309              0.0740              0.0025   \n",
      "26-35  0.3173                  0.1058              0.5535              0.0215   \n",
      "36-45  0.1088                  0.0363              0.7600              0.0815   \n",
      "46-60  0.0900                  0.0300              0.6833              0.1533   \n",
      "60+    0.1125                  0.0375              0.5417              0.0883   \n",
      "\n",
      "       Widowded  \n",
      "18-25    0.0000  \n",
      "26-35    0.0020  \n",
      "36-45    0.0135  \n",
      "46-60    0.0817  \n",
      "60+      0.3350  \n",
      "18-25 → χ² = 1.07, p = 0.784\n",
      "26-35 → χ² = 0.79, p = 0.940\n",
      "36-45 → χ² = 3.34, p = 0.503\n",
      "46-60 → χ² = 3.95, p = 0.413\n",
      "60+ → χ² = 3.09, p = 0.542\n",
      "Combined χ² = 12.24, p = 0.967\n",
      "expected: 6.08506899\n",
      "sigma: 2.4396463909703403\n",
      "obs: 5\n",
      "z: -0.4447648618324669\n",
      "left\n",
      "expected: 43.21276685\n",
      "sigma: 5.74532031699753\n",
      "obs: 35\n",
      "z: -1.429470664273066\n",
      "left\n",
      "expected: 98.27268192\n",
      "sigma: 5.821444423423054\n",
      "obs: 92\n",
      "z: -1.0775129785249435\n",
      "left\n",
      "expected: 271.59880332\n",
      "sigma: 9.053685145917013\n",
      "obs: 277\n",
      "z: 0.5965743885445147\n",
      "right\n",
      "observed: 277\n",
      "expected: 271.59880332\n",
      "             z_stat   p_value\n",
      "Age_Group                    \n",
      "0-24      -0.444765  0.328245\n",
      "25-34     -1.429471  0.076435\n",
      "35-44     -1.077513  0.140626\n",
      "45+        0.596574  0.275396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2536855/4138863116.py:198: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df_for_children.groupby(['Age_Group', 'Sex'])['Has_Children']\n",
      "/tmp/ipykernel_2536855/4138863116.py:253: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  counts = df_for_children.groupby(['Age_Group','Sex']).size()\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot join with no overlapping index names",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 271\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOverall child–prob: z = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mz_overall\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, p = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp_overall\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 271\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 260\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    257\u001b[0m exp_p \u001b[38;5;241m=\u001b[39m expected_df_children\u001b[38;5;241m.\u001b[39mstack()  \u001b[38;5;66;03m# Series indexed by (Age_Group,Sex)\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# 4) expected total count\u001b[39;00m\n\u001b[0;32m--> 260\u001b[0m E_tot \u001b[38;5;241m=\u001b[39m (\u001b[43mcounts\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mexp_p\u001b[49m)\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m    262\u001b[0m \u001b[38;5;66;03m# 5) overall expected probability\u001b[39;00m\n\u001b[1;32m    263\u001b[0m p_tot \u001b[38;5;241m=\u001b[39m E_tot \u001b[38;5;241m/\u001b[39m n_tot\n",
      "File \u001b[0;32m~/miniconda3/envs/patient_creator/lib/python3.10/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/patient_creator/lib/python3.10/site-packages/pandas/core/arraylike.py:202\u001b[0m, in \u001b[0;36mOpsMixin.__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__mul__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__mul__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m--> 202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/patient_creator/lib/python3.10/site-packages/pandas/core/series.py:6134\u001b[0m, in \u001b[0;36mSeries._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_arith_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, op):\n\u001b[0;32m-> 6134\u001b[0m     \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_align_for_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m base\u001b[38;5;241m.\u001b[39mIndexOpsMixin\u001b[38;5;241m.\u001b[39m_arith_method(\u001b[38;5;28mself\u001b[39m, other, op)\n",
      "File \u001b[0;32m~/miniconda3/envs/patient_creator/lib/python3.10/site-packages/pandas/core/series.py:6164\u001b[0m, in \u001b[0;36mSeries._align_for_op\u001b[0;34m(self, right, align_asobject)\u001b[0m\n\u001b[1;32m   6161\u001b[0m             left \u001b[38;5;241m=\u001b[39m left\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\n\u001b[1;32m   6162\u001b[0m             right \u001b[38;5;241m=\u001b[39m right\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\n\u001b[0;32m-> 6164\u001b[0m         left, right \u001b[38;5;241m=\u001b[39m \u001b[43mleft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malign\u001b[49m\u001b[43m(\u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   6166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m left, right\n",
      "File \u001b[0;32m~/miniconda3/envs/patient_creator/lib/python3.10/site-packages/pandas/core/generic.py:10447\u001b[0m, in \u001b[0;36mNDFrame.align\u001b[0;34m(self, other, join, axis, level, copy, fill_value, method, limit, fill_axis, broadcast_axis)\u001b[0m\n\u001b[1;32m  10434\u001b[0m     left, _right, join_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_align_frame(\n\u001b[1;32m  10435\u001b[0m         other,\n\u001b[1;32m  10436\u001b[0m         join\u001b[38;5;241m=\u001b[39mjoin,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10443\u001b[0m         fill_axis\u001b[38;5;241m=\u001b[39mfill_axis,\n\u001b[1;32m  10444\u001b[0m     )\n\u001b[1;32m  10446\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, ABCSeries):\n\u001b[0;32m> 10447\u001b[0m     left, _right, join_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_align_series\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  10448\u001b[0m \u001b[43m        \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10449\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10450\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10451\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_axis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  10457\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m  10458\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m  10459\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsupported type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(other)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/patient_creator/lib/python3.10/site-packages/pandas/core/generic.py:10564\u001b[0m, in \u001b[0;36mNDFrame._align_series\u001b[0;34m(self, other, join, axis, level, copy, fill_value, method, limit, fill_axis)\u001b[0m\n\u001b[1;32m  10562\u001b[0m     join_index, lidx, ridx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m  10563\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m> 10564\u001b[0m     join_index, lidx, ridx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  10565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_indexers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m  10566\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m  10568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_series:\n\u001b[1;32m  10569\u001b[0m     left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_indexer(join_index, lidx, copy)\n",
      "File \u001b[0;32m~/miniconda3/envs/patient_creator/lib/python3.10/site-packages/pandas/core/indexes/base.py:279\u001b[0m, in \u001b[0;36m_maybe_return_indexers.<locals>.join\u001b[0;34m(self, other, how, level, return_indexers, sort)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(meth)\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mjoin\u001b[39m(\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    277\u001b[0m     sort: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    278\u001b[0m ):\n\u001b[0;32m--> 279\u001b[0m     join_index, lidx, ridx \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_indexers:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m join_index\n",
      "File \u001b[0;32m~/miniconda3/envs/patient_creator/lib/python3.10/site-packages/pandas/core/indexes/base.py:4615\u001b[0m, in \u001b[0;36mIndex.join\u001b[0;34m(self, other, how, level, return_indexers, sort)\u001b[0m\n\u001b[1;32m   4613\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   4614\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4615\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_join_multi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4617\u001b[0m \u001b[38;5;66;03m# join on the level\u001b[39;00m\n\u001b[1;32m   4618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_multi \u001b[38;5;129;01mor\u001b[39;00m other\u001b[38;5;241m.\u001b[39m_is_multi):\n",
      "File \u001b[0;32m~/miniconda3/envs/patient_creator/lib/python3.10/site-packages/pandas/core/indexes/base.py:4739\u001b[0m, in \u001b[0;36mIndex._join_multi\u001b[0;34m(self, other, how)\u001b[0m\n\u001b[1;32m   4737\u001b[0m \u001b[38;5;66;03m# need at least 1 in common\u001b[39;00m\n\u001b[1;32m   4738\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m overlap:\n\u001b[0;32m-> 4739\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join with no overlapping index names\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, MultiIndex) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, MultiIndex):\n\u001b[1;32m   4742\u001b[0m     \u001b[38;5;66;03m# Drop the non-matching levels from left and right respectively\u001b[39;00m\n\u001b[1;32m   4743\u001b[0m     ldrop_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(self_names \u001b[38;5;241m-\u001b[39m overlap, key\u001b[38;5;241m=\u001b[39mself_names_order)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot join with no overlapping index names"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \n",
    "    df = pd.read_csv(file_path, delimiter = \"|\")\n",
    "    \n",
    "    print(\"\\n=== Statistical Tests and Graphs ===\\n\")\n",
    "    \n",
    "    # == Sex Analysis ==\n",
    "    analyze(df, 'Sex', SEX_WEIGHTS, \"Sex Distribution\")\n",
    "\n",
    "    # == Age Analysis== \n",
    "    df['Age_Category'] = df['Age'].apply(categorize_age)\n",
    "    expected_age_probs, age_groups = compute_expected_age_probs(df)\n",
    "    # Ensure the Age_Category is ordered correctly\n",
    "    df['Age_Category'] = pd.Categorical(df['Age_Category'], categories=age_groups, ordered=True)\n",
    "    analyze(df, 'Age_Category', expected_age_probs, \"Age Distribution\", order=age_groups)\n",
    "\n",
    "    # == Ethnicity Analysis ==\n",
    "    df[\"Ethnicity_Category\"] = df[\"Ethnicity\"].apply(categorize_ethnicity)\n",
    "    analyze(df, 'Ethnicity_Category', ETHNICITY_PROBABILITY, \"Ethnicity Distribution\", order=ETHNICITY_ORDER)\n",
    "    \n",
    "    # == Disability Analysis ==\n",
    "    df_yes_disability = df[df[\"Disabled\"] == \"Yes\"]\n",
    "    # 1) Parse and flatten the disability type lists\n",
    "    all_types = []\n",
    "\n",
    "    for val in df_yes_disability[\"Disability\"]:\n",
    "        if isinstance(val, str):\n",
    "            try:\n",
    "                parsed = ast.literal_eval(val)  # safely converts \"['mobility', 'vision']\" → list\n",
    "                if isinstance(parsed, list):\n",
    "                    all_types.extend(parsed)\n",
    "            except:\n",
    "                continue\n",
    "        elif isinstance(val, list):\n",
    "            all_types.extend(val)\n",
    "            \n",
    "    # 2) Count frequencies\n",
    "    type_counts = Counter(all_types)\n",
    "    # print(\"type counts:\", type_counts)\n",
    "    # total_obs = df_yes_disability.shape[0]\n",
    "    total_obs = sum(type_counts.values())\n",
    "    print(\"total obs:\", total_obs)\n",
    "\n",
    "    # 3) Build observed distribution dict\n",
    "    observed_disability = {\n",
    "        cat: type_counts.get(cat, 0) / total_obs\n",
    "        for cat in DISABILITY_CATEGORIES\n",
    "    }\n",
    "\n",
    "    expected_disability_df = df_yes_disability.apply(compute_expected_disability, axis=1)\n",
    "    expected_disability_avg = expected_disability_df.mean().to_dict()\n",
    "\n",
    "    categories = list(expected_disability_avg.keys())\n",
    "\n",
    "    observed_counts = pd.Series(type_counts)\n",
    "    observed_counts = observed_counts.reindex(DISABILITY_CATEGORIES)\n",
    "    print(\"counts:\" , observed_counts)\n",
    "    expected_counts = np.array([expected_disability_avg[cat] for cat in categories])\n",
    "\n",
    "    expected_probs = np.array(expected_counts) / np.sum(expected_counts)\n",
    "\n",
    "    # observed_counts = df_yes_disability['Disability'].value_counts().reindex(order, fill_value=0)\n",
    "\n",
    "    title=\"Disability Breakdown\"\n",
    "    chi_square_stat, p_value = multinomial_p_value(observed_counts.values, expected_probs)\n",
    "    print(f\"{title} - Chi-Square: {chi_square_stat:.2f}, P-value: {p_value:.4f}\")\n",
    "\n",
    "    # Rename columns\n",
    "    df.rename(columns={\n",
    "        \"Relationship Status\": \"Relationship_Status\",\n",
    "        \"Children\": \"Has_Children\",\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Simplify relationship statuses\n",
    "    relationship_mapping = {\n",
    "        \"Common-Law\": \"Married/Common-Law\",\n",
    "        \"Married\": \"Married/Common-Law\",\n",
    "        \"Divorced\": \"Divorced/Separated\",\n",
    "        \"Separated\": \"Divorced/Separated\"\n",
    "    }\n",
    "    df[\"Relationship_Status\"] = df[\"Relationship_Status\"].replace(relationship_mapping)\n",
    "    df[\"Relationship_Status\"] = df[\"Relationship_Status\"].astype(\"category\")\n",
    "\n",
    "\n",
    "    # Convert \"Has_Children\" to yes/no\n",
    "    df[\"Has_Children\"] = df[\"Has_Children\"].apply(\n",
    "        lambda x: \"Yes\" if x != 0 else \"No\"\n",
    "    )\n",
    "\n",
    "    # 1) Compute observed fractions using crosstab (normalized by row)\n",
    "    # df['Age_Category'] = df['Age'].apply(categorize_age)\n",
    "    observed_rel_df = pd.crosstab(df[\"Age_Category\"],\n",
    "                                  df[\"Relationship_Status\"],\n",
    "                                  normalize=\"index\")\n",
    "    observed_rel_df = observed_rel_df.reindex(index=AGE_ORDER,\n",
    "                                              columns=RELATIONSHIP_ORDER)\n",
    "\n",
    "    # 2) Build expected distribution from hard-coded RELATIONSHIP_STATUS_DISTRIBUTIONS\n",
    "    columns_for_rel = [\"Single\", \"Long-term Relationship\", \"Married/Common-law\",\n",
    "                       \"Divorced/Separated\", \"Widowed\"]\n",
    "    rel_df = pd.DataFrame(RELATIONSHIP_STATUS_DISTRIBUTIONS,\n",
    "                          index=AGE_ORDER,\n",
    "                          columns=columns_for_rel)\n",
    "\n",
    "    # 3) Rename columns to match observed naming\n",
    "    col_map = {\n",
    "        \"Long-term Relationship\": \"Long-term relationship\",\n",
    "        \"Married/Common-law\": \"Married/Common-Law\",\n",
    "        \"Widowed\": \"Widowded\"\n",
    "    }\n",
    "    rel_df.rename(columns=col_map, inplace=True)\n",
    "    expected_rel_df = rel_df.reindex(index=AGE_ORDER, columns=RELATIONSHIP_ORDER)\n",
    "\n",
    "    # 4) Convert from percentages (0-100) to fractions (0-1)\n",
    "    observed_matrix = observed_rel_df.values\n",
    "    expected_matrix = expected_rel_df.values / 100.0\n",
    "\n",
    "    # Convert the matrix form back into DataFrame (for the split-diagonal function)\n",
    "    obs_df_rel = pd.DataFrame(observed_matrix,\n",
    "                              index=AGE_ORDER,\n",
    "                              columns=RELATIONSHIP_ORDER)\n",
    "    exp_df_rel = pd.DataFrame(expected_matrix,\n",
    "                              index=AGE_ORDER,\n",
    "                              columns=RELATIONSHIP_ORDER)\n",
    "\n",
    "    print(\"obs:\", obs_df_rel)\n",
    "    print(\"exp:\", exp_df_rel)\n",
    "\n",
    "    \n",
    "    counts_rel_df = (\n",
    "        pd.crosstab(df[\"Age_Category\"], df[\"Relationship_Status\"])\n",
    "          .reindex(index=obs_df_rel.index,\n",
    "                   columns=obs_df_rel.columns,\n",
    "                   fill_value=0)\n",
    "        )\n",
    "\n",
    "\n",
    "    for age in obs_df_rel.index:\n",
    "        total_n    = counts_rel_df.loc[age].sum()\n",
    "        obs_counts = obs_df_rel.loc[age].values * total_n\n",
    "        exp_probs  = exp_df_rel.loc[age].values\n",
    "\n",
    "        # compute expected counts and re-normalize\n",
    "        exp_counts = exp_probs * total_n\n",
    "        # exp_counts = exp_counts / exp_counts.sum() * total_n\n",
    "\n",
    "        # drop any zero-expected bins\n",
    "        mask = exp_counts > 0\n",
    "        oc = obs_counts[mask]\n",
    "        ec = exp_counts[mask]\n",
    "\n",
    "        chi2, p = stats.chisquare(f_obs=oc, f_exp=ec, sum_check = False)\n",
    "        print(f\"{age} → χ² = {chi2:.2f}, p = {p:.3f}\")\n",
    "\n",
    "\n",
    "    # 1) compute the total-N for each age group\n",
    "    total_n = counts_rel_df.sum(axis=1)     # a Series indexed by age\n",
    "\n",
    "    # 2) get the observed counts matrix: age × status\n",
    "    obs_matrix = obs_df_rel.mul(total_n, axis=0).values\n",
    "\n",
    "    # 3) get the expected counts matrix: age × status\n",
    "    exp_matrix = exp_df_rel.mul(total_n, axis=0).values\n",
    "    \n",
    "    # 4) flatten to 1d\n",
    "    f_obs = obs_matrix.flatten()\n",
    "    f_exp = exp_matrix.flatten()\n",
    "\n",
    "    # 6) renormalize expected counts to match the observed total exactly\n",
    "    # f_exp = f_exp / f_exp.sum() * f_obs.sum()\n",
    "\n",
    "    # 5) drop any zero‐expected bins (to avoid division-by-zero)\n",
    "    mask = f_exp > 0\n",
    "    f_obs = f_obs[mask]\n",
    "    f_exp = f_exp[mask]\n",
    "\n",
    "    # 7) run χ²\n",
    "    chi2_all, p_all = stats.chisquare(f_obs=f_obs, f_exp=f_exp, sum_check=False)\n",
    "    print(\"Combined χ² = %.2f, p = %.3f\" % (chi2_all, p_all))\n",
    "\n",
    "\n",
    "    # 1) Use the entire DataFrame\n",
    "    df_for_children = df.copy()  # or df_for_children = df\n",
    "\n",
    "    # 2) Define the new bins and labels: [0,25), [25,35), [35,45), [45,∞)\n",
    "    age_bins = [0, 25, 35, 45, float('inf')]\n",
    "    age_labels = ['0-24', '25-34', '35-44', '45+']\n",
    "\n",
    "    df_for_children['Age_Group'] = pd.cut(\n",
    "        df_for_children['Age'],\n",
    "        bins=age_bins,\n",
    "        labels=age_labels,\n",
    "        right=False\n",
    "    )\n",
    "\n",
    "    # 3) Compute observed fraction with children (pivot into 2D table)\n",
    "    observed_counts = (\n",
    "        df_for_children.groupby(['Age_Group', 'Sex'])['Has_Children']\n",
    "                       .value_counts(normalize=True)\n",
    "                       .unstack(fill_value=0)\n",
    "    )\n",
    "    observed_df_children = (\n",
    "        observed_counts[['Yes']]  # we only need the \"Yes\" column\n",
    "        .reset_index()\n",
    "        .pivot(index='Age_Group', columns='Sex', values='Yes')\n",
    "    )\n",
    "\n",
    "    # 4) Build the expected fraction with children\n",
    "    expected_dict_children = {}\n",
    "    for i, label in enumerate(age_labels):\n",
    "        # Probability = in_family[i][sex_idx] * with_children[i][0]\n",
    "        female_prob = IN_FAMILY[i][0] * WITH_CHILDREN[i][1]\n",
    "        male_prob   = IN_FAMILY[i][1] * WITH_CHILDREN[i][1]\n",
    "        expected_dict_children[(label, \"Female\")] = female_prob\n",
    "        expected_dict_children[(label, \"Male\")]   = male_prob\n",
    "\n",
    "    expected_series_children = pd.Series(expected_dict_children)\n",
    "    expected_df_children = expected_series_children.unstack()\n",
    "    \n",
    "    results = []\n",
    "    for age in expected_df_children.index:            # e.g. '0-24', '25-34',...\n",
    "        # 1) subset to this age group\n",
    "        sub = df_for_children[df_for_children['Age_Group'] == age]\n",
    "        n   = len(sub)\n",
    "        k   = sub['Has_Children'].eq('Yes').sum()\n",
    "\n",
    "        # 2) build weighted expected probability p0 for this age:\n",
    "        #    take each sex’s expected p and weight by how many of that sex are in this age\n",
    "        counts_by_sex = sub['Sex'].value_counts().reindex(expected_df_children.columns, fill_value=0)\n",
    "        p_by_sex      = expected_df_children.loc[age]   # a Series: index ['Female','Male']\n",
    "        p0 = (counts_by_sex * p_by_sex).sum() / counts_by_sex.sum()\n",
    "\n",
    "        # 3) call your helper\n",
    "        z_stat, p_val = binomial_p_value(n, p0, k)\n",
    "\n",
    "        results.append({\n",
    "            'Age_Group': age,\n",
    "            'n'        : n,\n",
    "            'k'        : k,\n",
    "            'exp_p0'   : p0,\n",
    "            'z_stat'   : z_stat,\n",
    "            'p_value'  : p_val\n",
    "        })\n",
    "\n",
    "    age_df = pd.DataFrame(results).set_index('Age_Group')\n",
    "    print(age_df[['z_stat','p_value']])\n",
    "\n",
    "    # 1) total N and total k\n",
    "    n_tot = len(df_for_children)\n",
    "    k_tot = df_for_children['Has_Children'].eq('Yes').sum()\n",
    "\n",
    "    # 2) get counts per (Age_Group, Sex)\n",
    "    counts = df_for_children.groupby(['Age_Group','Sex']).size()\n",
    "\n",
    "    # 3) get expected p per cell as a Series with the same MultiIndex\n",
    "    #    expected_df_children: index=Age_Group, columns=Sex\n",
    "    exp_p = expected_df_children.stack()  # Series indexed by (Age_Group,Sex)\n",
    "\n",
    "    # 4) expected total count\n",
    "    E_tot = (counts * exp_p).sum()\n",
    "\n",
    "    # 5) overall expected probability\n",
    "    p_tot = E_tot / n_tot\n",
    "\n",
    "    # 6) get overall z and p-value\n",
    "    z_overall, p_overall = binomial_p_value(n_tot, p_tot, k_tot)\n",
    "\n",
    "    print(f\"Overall child–prob: z = {z_overall:.4f}, p = {p_overall:.4f}\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7f681c-8299-4827-96ee-57a5712e582b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (patient_creator)",
   "language": "python",
   "name": "patient_creator"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
