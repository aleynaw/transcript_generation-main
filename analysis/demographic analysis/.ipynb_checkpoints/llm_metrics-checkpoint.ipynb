{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f736da3-08c5-43b7-a54f-58b3bfc71f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, statistics, textwrap\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from collections import Counter\n",
    "\n",
    "output_dir = \"plots\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load the spreadsheet\n",
    "file_path = \"llm_patients_040725.csv\"\n",
    "df = pd.read_csv(file_path, delimiter=\"|\")\n",
    "\n",
    "# Use a smoothing function to handle low-overlap n-gram cases\n",
    "smoothing_fn = SmoothingFunction().method1\n",
    "\n",
    "# Define relevant columns\n",
    "llm_columns = [\n",
    "    \"Children Details\", \"Family History of Health Conditions Details\", \"Sibling Details\",\n",
    "    \"Previous Work History\", \"Previous Marriages/Long-Term Relationships\",\n",
    "    \"Hobbies\", \"Relaxation Methods\", \"Rehab or Substance Counselling\",\n",
    "    \"Previous Hospitalizations or Surgeries Details\", \"Head Injuries or Concussions Details\",\n",
    "    \"Disability Details\", \"Disability Assistance Details\"\n",
    "]\n",
    "\n",
    "llm_columns_abbr = [\n",
    "    \"Children Details\", \"Family Health Hx Details\", \"Sibling Details\",\n",
    "    \"Work Hx\", \"Past Marriages/Relationships\", \"Hobbies\", \"Relaxation Methods\", \n",
    "    \"Substance Rehab/Counselling\", \"Hosp./Surgeries Details\", \"Head Injuries/Concussions Details\",\n",
    "    \"Disability Details\", \"Disability Assistance Details\"\n",
    "]\n",
    "\n",
    "\n",
    "# Define function to wrap labels\n",
    "def wrap_labels(labels, width=20):\n",
    "    return [textwrap.fill(label, width) for label in labels]\n",
    "\n",
    "def plot_graphs(df_index, df_, ylabel, title, savefig=True):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(df_index, df_, color='blue')\n",
    "    # Wrap x-tick labels for better readability\n",
    "    wrapped_labels = wrap_labels(df_index)\n",
    "    plt.xticks(ticks=range(len(df_index)), labels=wrapped_labels, rotation=90)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    if savefig:\n",
    "        filename = f\"{output_dir}/{title.replace(' ', '_').lower()}.png\"\n",
    "        plt.savefig(filename, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_graphs_std(df_index, df_, std, ylabel, title, savefig=True):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(df_index, df_, color='blue', yerr=std, capsize=5)\n",
    "    # Wrap x-tick labels\n",
    "    wrapped_labels = wrap_labels(df_index)\n",
    "    plt.xticks(ticks=range(len(df_index)), labels=wrapped_labels, rotation=90)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    if savefig:\n",
    "        filename = f\"{output_dir}/{title.replace(' ', '_').lower()}.png\"\n",
    "        plt.savefig(filename, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdcfdfcf-4edd-4f36-82b2-7917e6fd28d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_ngrams' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 97\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(all_ngrams)) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_ngrams)\n\u001b[0;32m---> 97\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mall_ngrams\u001b[49m)\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# def compute_self_bleu_optimized(text_series, sample_size=1000):\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m#     \"\"\"Computes Self-BLEU score using a sample of the dataset to speed up computation.\"\"\"\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m#     non_empty_texts = text_series.dropna().tolist()\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m#     return sum(bleu_scores) / len(bleu_scores)\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_most_common_ngrams\u001b[39m(text_series, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, top_n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_ngrams' is not defined"
     ]
    }
   ],
   "source": [
    "def bootstrap_sample(data, llm_columns, n_samples=1000, sample_size=None):\n",
    "    \"\"\"\n",
    "    Perform bootstrapping on a dataset and apply three metrics separately for each column.\n",
    "    \n",
    "    Parameters:\n",
    "        data (pd.DataFrame): The dataset to bootstrap.\n",
    "        llm_columns (list): List of column names to evaluate.\n",
    "        n_samples (int): Number of bootstrap samples to generate.\n",
    "        sample_size (int, optional): Size of each bootstrap sample (default is size of original dataset).\n",
    "    \n",
    "    Returns:\n",
    "        dict: Bootstrap results containing metrics for each column separately.\n",
    "    \"\"\"\n",
    "    if sample_size is None:\n",
    "        sample_size = len(data)\n",
    "\n",
    "    # Store results separately for each column\n",
    "    results = {col: {\"dup_ratio\": [], \"distinct_1\": [], \"global_dis_1\": []} for col in llm_columns}\n",
    "\n",
    "    ## Column: Children Details:\n",
    "    ##         \"self_bleu\": [x, x1, x2... x1000],\n",
    "    ##          \"\"\n",
    "    ## ...\n",
    "    ## Column: \n",
    "    i = 0\n",
    "    for _ in range(n_samples):\n",
    "        i += 1\n",
    "        # print(i)\n",
    "        sample = data.sample(n=sample_size, replace=True)\n",
    "\n",
    "        for col in llm_columns: \n",
    "            non_empty_entries = sample[col].dropna() # list or df\n",
    "            unique_count = non_empty_entries.nunique() # number\n",
    "            duplicate_count = len(non_empty_entries) - unique_count  # Total - unique = int\n",
    "\n",
    "            # Compute metrics\n",
    "            # bleu_score = compute_self_bleu_optimized(sample[col])\n",
    "            dup_ratio = duplicate_count / len(non_empty_entries) if len(non_empty_entries) > 0 else 0\n",
    "            distinct_1_score = compute_distinct_ngram_ratio(non_empty_entries, n=1)\n",
    "            global_distinct_1 = compute_global_distinct_n(non_empty_entries, n=1)\n",
    "\n",
    "            # Store results\n",
    "            # results[col][\"self_bleu\"].append(bleu_score)\n",
    "            results[col][\"dup_ratio\"].append(dup_ratio)\n",
    "            results[col][\"distinct_1\"].append(distinct_1_score)\n",
    "            results[col][\"global_dis_1\"].append(global_distinct_1)\n",
    "\n",
    "    return results\n",
    "\n",
    "def compute_distinct_ngram_ratio(text_series, n=1):\n",
    "    \"\"\"Computes the distinct-n ratio (Distinct-1 for unigrams, Distinct-2 for bigrams)\"\"\"\n",
    "    all_scores = []\n",
    "    for text in text_series.dropna():\n",
    "        words = text.lower().split()\n",
    "        # ngrams = [' '.join(words[i:i+n]) for i in range(len(words)-n+1)]\n",
    "        total_words = len(words)\n",
    "        unique_words = len(set(words))\n",
    "        if total_words > 0:\n",
    "            distinct_1_score = unique_words/total_words\n",
    "        else:\n",
    "            distinct_1_score = 0\n",
    "        all_scores.append(distinct_1_score)\n",
    "    \n",
    "    average = statistics.fmean(all_scores)\n",
    "    return average\n",
    "\n",
    "def compute_global_distinct_n(text_series, n=1):\n",
    "    \"\"\"\n",
    "    Computes the fraction of all n-grams in `text_series` that are unique\n",
    "    (i.e. |set(ngrams)| / total # of ngrams).\n",
    "    \"\"\"\n",
    "    all_ngrams = []\n",
    "    for text in text_series.dropna():\n",
    "        words = text.lower().split()\n",
    "        all_ngrams += [' '.join(words[i:i+n]) for i in range(len(words)-n+1)]\n",
    "    if not all_ngrams:\n",
    "        return 0.0\n",
    "    return len(set(all_ngrams)) / len(all_ngrams)\n",
    "\n",
    "def compute_batch_global_distinct_n(df, columns, n=1):\n",
    "    \"\"\"\n",
    "    Computes distinct-n over the concatenation of text in `columns`.\n",
    "    (i.e. |set(all n-grams)| / total # of n-grams).\n",
    "    \"\"\"\n",
    "    all_ngrams = []\n",
    "    for col in columns:\n",
    "        for text in df[col].dropna():\n",
    "            words = text.lower().split()\n",
    "            all_ngrams += [\n",
    "                ' '.join(words[i:i+n])\n",
    "                for i in range(len(words)-n+1)\n",
    "            ]\n",
    "    if not all_ngrams:\n",
    "        return 0.0\n",
    "\n",
    "    print(all_ngrams)\n",
    "    return len(set(all_ngrams)) / len(all_ngrams)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def compute_self_bleu_optimized(text_series, sample_size=1000):\n",
    "#     \"\"\"Computes Self-BLEU score using a sample of the dataset to speed up computation.\"\"\"\n",
    "#     non_empty_texts = text_series.dropna().tolist()\n",
    "#     if len(non_empty_texts) < 2:\n",
    "#         return None\n",
    "    \n",
    "#     if len(non_empty_texts) > sample_size:\n",
    "#         non_empty_texts = non_empty_texts[:sample_size]\n",
    "    \n",
    "#     bleu_scores = []\n",
    "#     for i, reference in enumerate(non_empty_texts):\n",
    "#         hypotheses = non_empty_texts[:i] + non_empty_texts[i+1:]\n",
    "#         bleu_score = sentence_bleu(\n",
    "#             [hypothesis.split() for hypothesis in hypotheses],\n",
    "#             reference.split(),\n",
    "#             weights=(0.25, 0.25, 0.25, 0.25),\n",
    "#             smoothing_function=smoothing_fn\n",
    "#         )\n",
    "#         bleu_scores.append(bleu_score)\n",
    "    \n",
    "#     return sum(bleu_scores) / len(bleu_scores)\n",
    "\n",
    "def get_most_common_ngrams(text_series, n=2, top_n=10):\n",
    "    \"\"\"Extracts the most common n-grams from a column.\"\"\"\n",
    "    ngram_counter = Counter()\n",
    "    for text in text_series.dropna():\n",
    "        words = text.lower().split()\n",
    "        ngrams = [' '.join(words[i:i+n]) for i in range(len(words)-n+1)]\n",
    "        ngram_counter.update(ngrams)\n",
    "    return ngram_counter.most_common(top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91db5181-82c8-4189-ac0f-db8978a7533f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_standard_deviation(bootstrap_results, sample_size=1000):\n",
    "    \"\"\"\n",
    "    Compute standard deviation for each metric across bootstrap samples.\n",
    "    \n",
    "    Parameters:\n",
    "        bootstrap_results (dict): Dictionary containing bootstrap results per column.\n",
    "        sample_size (int): Sample size used for bootstrapping.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing standard deviations per metric for each column.\n",
    "    \"\"\"\n",
    "    std_devs = {col: {} for col in bootstrap_results}\n",
    "\n",
    "    for col, metrics in bootstrap_results.items():\n",
    "        for metric, values in metrics.items():\n",
    "            values = np.array(values)\n",
    "            variance = (sample_size * values) * (1 - values)\n",
    "            standard_dev = np.sqrt(variance) / sample_size\n",
    "            std_devs[col][metric] = np.mean(standard_dev)  # Averaging across all bootstrap samples\n",
    "\n",
    "    return std_devs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee345ad-f716-45c2-ac24-0361a989dd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recalculate duplicate ratios only for non-empty entries in each LLM-generated column\n",
    "adjusted_repetition_stats = {}\n",
    "\n",
    "for col in llm_columns:\n",
    "    non_empty_entries = df[col].dropna()\n",
    "    unique_count = non_empty_entries.nunique()\n",
    "    duplicate_count = len(non_empty_entries) - unique_count  # Total - unique\n",
    "    adjusted_duplicate_ratio = duplicate_count / len(non_empty_entries) if len(non_empty_entries) > 0 else 0\n",
    "    distinct_1 = compute_distinct_ngram_ratio(non_empty_entries, n=1)\n",
    "    global_distinct_1 = compute_global_distinct_n(non_empty_entries, n=1)\n",
    "\n",
    "    adjusted_repetition_stats[col] = {\n",
    "        \"Total Non-Empty Entries\": len(non_empty_entries),\n",
    "        \"Unique Entries\": unique_count,\n",
    "        \"Duplicated Entries\": duplicate_count,\n",
    "        \"Adjusted Duplicate Ratio\": adjusted_duplicate_ratio,\n",
    "        \"Distinct-1 (Unigram Diversity)\": distinct_1,\n",
    "        \"Global Distinct-1\": global_distinct_1\n",
    "    }\n",
    "\n",
    "batch_distinct1 = compute_batch_global_distinct_n(df, llm_columns, n=1)\n",
    "print(f\"Batch Global Distinct-1 (all columns): {batch_distinct1:.3f}\")\n",
    "\n",
    "# Convert to DataFrame for better visualization\n",
    "adjusted_repetition_df = pd.DataFrame.from_dict(adjusted_repetition_stats, orient='index')\n",
    "\n",
    "# Generate updated visualizations\n",
    "# plot_graphs(df_index, df, ylabel, title, savefig=True)\n",
    "\n",
    "# Bar chart for adjusted duplicate ratio\n",
    "plot_graphs(llm_columns_abbr, adjusted_repetition_df[\"Adjusted Duplicate Ratio\"], \"Adjusted Duplicate Ratio\", \"Adjusted Duplicate Ratio Across LLM-Generated Columns\")\n",
    "\n",
    "# Bar chart for Distinct-1 (Unigram Diversity)\n",
    "plot_graphs(llm_columns_abbr, adjusted_repetition_df[\"Distinct-1 (Unigram Diversity)\"], \"Distinct-1 Score\", \"Distinct-1 (Unigram Diversity) Across LLM-Generated Columns\")\n",
    "\n",
    "plot_graphs(llm_columns_abbr, adjusted_repetition_df[\"Global Distinct-1\"], \"Global Distinct-1 Score\", \"Global Distinct-1 Across LLM-Generated Columns\")\n",
    "\n",
    "# Print adjusted statistics\n",
    "# print(adjusted_repetition_df)\n",
    "\n",
    "# Compute optimized Self-BLEU for each LLM-generated column\n",
    "# optimized_self_bleu_scores = {col: compute_self_bleu_optimized(df[col]) for col in llm_columns}\n",
    "\n",
    "# Convert to DataFrame\n",
    "# optimized_self_bleu_df = pd.DataFrame.from_dict(optimized_self_bleu_scores, orient='index', columns=[\"Optimized Self-BLEU Score\"])\n",
    "\n",
    "# Generate visualization: Bar chart for Self-BLEU scores\n",
    "# plot_graphs(llm_columns_abbr, optimized_self_bleu_df[\"Optimized Self-BLEU Score\"], \"Self-BLEU Score\", \"Self-BLEU Scores Across LLM-Generated Columns\")\n",
    "\n",
    "# Identify most repetitive phrases in high Self-BLEU columns\n",
    "# high_repetition_columns = optimized_self_bleu_df[optimized_self_bleu_df[\"Optimized Self-BLEU Score\"] > 0.6].index.tolist()\n",
    "# repetitive_phrases = {}\n",
    "# for col in high_repetition_columns:\n",
    "#     bigrams = get_most_common_ngrams(df[col], n=2)\n",
    "#     trigrams = get_most_common_ngrams(df[col], n=3)\n",
    "#     repetitive_phrases[col] = {\"Most Common Bigrams\": bigrams, \"Most Common Trigrams\": trigrams}\n",
    "\n",
    "# Convert to DataFrame\n",
    "# repetitive_phrases_df = pd.DataFrame.from_dict(repetitive_phrases, orient='index')\n",
    "\n",
    "# Save repetitive phrases analysis\n",
    "# repetitive_phrases_df.to_csv(\"repetitive_phrases.csv\")\n",
    "\n",
    "# Display updated statistics\n",
    "# print(optimized_self_bleu_df)\n",
    "# print(repetitive_phrases_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857fe2a4-6d75-4316-bc8c-15456988faf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## bootstrapping\n",
    "bootstrap_results = bootstrap_sample(df, llm_columns, n_samples=1000)\n",
    "standard_devs = compute_standard_deviation(bootstrap_results)\n",
    "\n",
    "# Print results\n",
    "for col in llm_columns:\n",
    "    print(f\"Column: {col}\")\n",
    "    for metric, std in standard_devs[col].items():\n",
    "        print(f\"  {metric}: {std:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67abd293-4339-4bcd-9368-34ebe8be819b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract standard deviations for duplicate ratio\n",
    "standard_devs_dup = [standard_devs[col][\"dup_ratio\"] for col in adjusted_repetition_df.index]\n",
    "\n",
    "# Extract standard deviations for Distinct-1\n",
    "standard_devs_distinct = [standard_devs[col][\"distinct_1\"] for col in adjusted_repetition_df.index]\n",
    "\n",
    "standard_devs_global_dis = [standard_devs[col][\"global_dis_1\"] for col in adjusted_repetition_df.index]\n",
    "# Extract standard deviations for Self-BLEU\n",
    "# standard_devs_bleu = [standard_devs[col][\"self_bleu\"] for col in optimized_self_bleu_df.index]\n",
    "\n",
    "# Plot Adjusted Duplicate Ratio\n",
    "plot_graphs_std(\n",
    "    llm_columns_abbr,\n",
    "    adjusted_repetition_df[\"Adjusted Duplicate Ratio\"],\n",
    "    standard_devs_dup,\n",
    "    \"Adjusted Duplicate Ratio\",\n",
    "    \"Adjusted Duplicate Ratio Across LLM-Generated Columns\"\n",
    ")\n",
    "\n",
    "# Plot Distinct-1 (Unigram Diversity)\n",
    "plot_graphs_std(\n",
    "    llm_columns_abbr,\n",
    "    adjusted_repetition_df[\"Distinct-1 (Unigram Diversity)\"],\n",
    "    standard_devs_distinct,\n",
    "    \"Distinct-1 Score\",\n",
    "    \"Distinct-1 (Unigram Diversity) Across LLM-Generated Columns\"\n",
    ")\n",
    "\n",
    "plot_graphs_std(\n",
    "    llm_columns_abbr,\n",
    "    adjusted_repetition_df[\"Global Distinct-1\"],\n",
    "    standard_devs_global_dis,\n",
    "    \"Global Distinct-1 Score\",\n",
    "    \"Global Distinct-1 Across LLM-Generated Columns\"\n",
    ")\n",
    "\n",
    "# Plot Self-BLEU Scores\n",
    "# plot_graphs_std(\n",
    "#     llm_columns_abbr,\n",
    "#     optimized_self_bleu_df[\"Optimized Self-BLEU Score\"],\n",
    "#     standard_devs_bleu,\n",
    "#     \"Self-BLEU Score\",\n",
    "#     \"Self-BLEU Scores Across LLM-Generated Columns\"\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5f333f-739d-448f-8bb5-2057c06b1322",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (patient_creator)",
   "language": "python",
   "name": "patient_creator"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
