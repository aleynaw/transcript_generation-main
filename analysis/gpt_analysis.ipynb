{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/ytcao/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys\n",
    "import random\n",
    "import time\n",
    "from dotenv.main import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "from openai import OpenAI\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "from collections import defaultdict\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import ast\n",
    "\n",
    "import nltk\n",
    "from nltk import tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### gpt-3-turbo #######\n",
    "# model_name = \"gpt-3.5-turbo-0125\"\n",
    "# pricing_in = 0.0005 #per 1K tokens\n",
    "# pricing_out = 0.0015 #per 1K tokens\n",
    "\n",
    "####### gpt-4-turbo #######\n",
    "model_name = \"gpt-4-0125-preview\"\n",
    "pricing_in = 0.01 #per 1K tokens\n",
    "pricing_out = 0.03 #per 1K tokens\n",
    "\n",
    "client = OpenAI(\n",
    "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
    "    api_key=openai_api_key,\n",
    ")\n",
    "temp = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_MODELS = {\n",
    "    \"gpt-3.5-turbo-0125\":{\n",
    "        \"pricing_in\": 0.0005,\n",
    "        \"pricing_out\":0.0015},\n",
    "    \"gpt-4-0125-preview\":{\n",
    "        \"pricing_in\":0.01,\n",
    "        \"pricing_out\":0.03\n",
    "    }\n",
    "}\n",
    "\n",
    "def get_gpt_response(messages_list, model_name=model_name, temperature=temp):\n",
    "    '''obtain response from chatgpt'''\n",
    "    assert model_name in [key for key in GPT_MODELS.keys()], f\"make sure {model_name} is one of the following: {[key for key in GPT_MODELS.keys()]}\"\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "            messages=messages_list,\n",
    "            model=model_name,\n",
    "            temperature=temperature,\n",
    "        )\n",
    "    \n",
    "    content = completion.choices[0].message.content\n",
    "    tokens_input = completion.usage.prompt_tokens\n",
    "    tokens_output = completion.usage.completion_tokens\n",
    "\n",
    "    completion_price = int(tokens_output)*GPT_MODELS[model_name]['pricing_out']/1000\n",
    "    prompt_price = int(tokens_input)*GPT_MODELS[model_name]['pricing_in']/1000\n",
    "    total_price = completion_price+prompt_price\n",
    "    # print(total_price)\n",
    "\n",
    "    return content, total_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patient analysis functions\n",
    "def get_user_summary(patient_lines):\n",
    "    user_summary_prompt = f'''\n",
    "    Your task is to summarize the patient's responses during a psychiatric interview. The patient's responses are enclosed in <patient-lines> tags.\n",
    "\n",
    "    <patient-lines>\n",
    "    {patient_lines}\n",
    "    </patient-lines>\n",
    "\n",
    "    Extract details from <patient-lines> into this list, referring to the relevant line number(s) when filling in any information. If a category in this list is not mentioned by the patient, fill in the category with \"Not mentioned\". If the patient expresses any hesitancy in responding, mention \"Expressed hesitancy\" when filling in the category.\n",
    "\n",
    "    Name:\n",
    "    Date of Birth:\n",
    "    Occupation:\n",
    "    Medical Conditions:\n",
    "    Medications:\n",
    "    Address:\n",
    "    Allergies:\n",
    "    Relationship Status:\n",
    "    Elementary School Performance:\n",
    "    High School Performance:\n",
    "    Canadian Citizenship:\n",
    "    Children:\n",
    "    Siblings:\n",
    "    Seizures:\n",
    "    Developmental Difficulties:\n",
    "    Family History of Health Conditions:\n",
    "    Previous Hospitalization:\n",
    "    Disability Assistance:\n",
    "    Past Trauma:\n",
    "    Substance Abuse:\n",
    "    Recreational Drug Usage:\n",
    "    '''\n",
    "    content, cost = get_gpt_response([{\"role\": \"user\", \"content\": user_summary_prompt}])\n",
    "    return content, cost\n",
    "\n",
    "def get_user_coverage(patient_info, patient_transcript_summary):\n",
    "    patient_info_rmv = [info for info in patient_info.split(\"\\n\") if info.split(\":\")[0] not in [\"Typing Style\",\"Sex\",\"Age\",\"Conversational Tone\"]]\n",
    "    coverage_prompt = f'''\n",
    "    Score the following a typed patient interview summary with respect to coverage relating to the Patient Information on a continuous scale from 0 to 100, where a score of zero means \"no coverage\" and a score of one hundred means \"perfect coverage\". \n",
    "\n",
    "    Note that coverage measures whether or not the characteristic content in Interview Summary match the characteristic content given in Patient Information. For example, if \"Previous Hospitalization\" is marked as \"no\" in Patient Information but a detailed history is reported in Interview Summary, this should be treated as no coverage. If \"Allergies\" contains two allergens in Patient Information but only one is reported in Interview Summary, this should be treated as incomplete coverage. Score this based only on characteristics present in the Interview Summary. Ignore Reason for Appointment, Typing Style and Conversational Tone.\n",
    "\n",
    "    Reason through your thought process, and output your score at the very end after a \"### Score\" header. This should be the last output.\n",
    "\n",
    "    Patient Information:\n",
    "    {patient_info_rmv}\n",
    "\n",
    "    Interview Summary: \n",
    "    {patient_transcript_summary}\n",
    "    '''\n",
    "    content, cost = get_gpt_response([{\"role\": \"user\", \"content\": coverage_prompt}])\n",
    "    try:\n",
    "        specificity_val = int(content.split(\"### Score\")[-1][:4].strip())\n",
    "    except ValueError:\n",
    "        specificity_val = np.NaN\n",
    "    return content, specificity_val, cost\n",
    "\n",
    "def get_user_edge_case_present(patient_lines):\n",
    "    edge_case = \"Upon first talking about any medication, misspell the medication name.\"\n",
    "\n",
    "    edge_case_prompt = f'''\n",
    "    Determine whether or not the provided transcript edge case is found within the message list. This message list represents only one person's side of a conversation.\n",
    "\n",
    "    Your answer should have either \"Final Answer: True\" or \"Final Answer: False\" at the end of the transcript. Include the lines relevant to the edge case in your response to me. \n",
    "    \n",
    "    For example, your response might look like \"The lines that are relevant to the edge case are '15. I take Aderall.' and '16. Sorry, yeah, I meant Adderall.' These lines imply that the name of the medication was misspelled. Final Answer: True.\" or \"The line that is relevant to the edge case is '15. I take Adderall.' This line implies that the name of the medication was not misspelled. Final Answer: False\"\n",
    "\n",
    "    Edge Case: {edge_case}\n",
    "    Transcript: {patient_lines}\n",
    "    '''\n",
    "    content, cost = get_gpt_response([{\"role\": \"user\", \"content\": edge_case_prompt}])\n",
    "    return content, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_asst_edge_case_present(asst_lines):\n",
    "    # edge_case = \"Ask a follow-up question to verify the medication dosage.\"\n",
    "    edge_case = \"Correct the medication name misspelling by suggesting the correct medication name.\"\n",
    "\n",
    "    # edge_case_prompt = f'''\n",
    "    # Determine whether or not the provided transcript edge case is consistent with the contents in the transcript. \n",
    "    \n",
    "    # Your answer should be either True or False. If True, also include a \"|\" character, followed by the line that the edge case occurs at. If False, only output \"False\". For examples, \"True|16. Could you check your medication dosage?\" or \"False\"\n",
    "\n",
    "    # Edge Case: {edge_case}\n",
    "    # Transcript: {asst_lines}\n",
    "    # '''\n",
    "    edge_case_prompt = f'''\n",
    "    Determine whether or not the provided transcript edge case is found within the message list. This message list represents only one person's side of a conversation.\n",
    "\n",
    "    Your answer should have either \"Final Answer: True\" or \"Final Answer: False\" at the end of the transcript. Include the lines relevant to the edge case in your response to me. \n",
    "\n",
    "    For example, your response might look like \"The lines that are relevant to the edge case are '15. What medications are you taking?' and '16. Did you mean Adderall?'. These lines imply that the name of the medication was suggested. Final Answer: True.\" or \"The lines that are relevant to the edge case are '15. What medications are you taking?' and '16. Thank you for letting me know.'. These lines imply that the name of the medication was not corrected. Final Answer: False\"\n",
    "\n",
    "    Edge Case: {edge_case}\n",
    "    Transcript: {asst_lines}\n",
    "    '''\n",
    "\n",
    "    content, cost = get_gpt_response([{\"role\": \"user\", \"content\": edge_case_prompt}])\n",
    "    return content, cost\n",
    "\n",
    "def get_asst_coverage(filtered_qb_list, asst_msgs):\n",
    "    question_bank_str = \"\\n\".join(filtered_qb_list)\n",
    "    asst_msgs_str = \"\\n\".join([f\"{i}. {msg}\" for i, msg in enumerate(asst_msgs)])\n",
    "    coverage_prompt = f'''\n",
    "    Score the following list of Assistant Interview Messages with respect to coverage of the Question Bank on a continuous scale from 0 to 100, where a score of zero means \"no coverage\" and a score of one hundred means \"perfect coverage\". \n",
    "\n",
    "    Note that coverage measures whether or not each question in the Question Bank is addressed in Assistant Interview Messages. For every question in the Question Bank, label it as \"Addressed\" or \"Not addressed\" based on the Interview Messages. State message number to provide evidence for that label (e.g., \"- birth complications - Addressed (8)\"). Use these labels to assign a score.\n",
    "\n",
    "    Output your score at the very end after a \"### Score\" header. (e.g., ### Score\\nXX)\n",
    "\n",
    "    Question Bank:\n",
    "    {question_bank_str}\n",
    "\n",
    "    Assistant Interview Messages: \n",
    "    {asst_msgs_str}\n",
    "    '''\n",
    "    content, cost = get_gpt_response([{\"role\": \"user\", \"content\": coverage_prompt}])\n",
    "    try:\n",
    "        specificity_val = int(content.split(\"### Score\")[-1][:4].strip())\n",
    "    except ValueError:\n",
    "        specificity_val = np.NaN\n",
    "    return content, specificity_val, cost\n",
    "\n",
    "\n",
    "def get_sentence_category(asst_msgs):\n",
    "    '''\n",
    "    return\n",
    "    ------\n",
    "    category_list : list\n",
    "        list of either \"Opening Question\", \"In-depth Question\", \"Empathy Statement\", or \"Other\". Length of list is the number of sentences expressed.\n",
    "    category_per_msg : dict\n",
    "        dict where keys are the index of each assistant message, and keys are the individual sentence categories. len(category_per_msg) = len(asst_msgs)\n",
    "    qs_per_msg : dict\n",
    "        dict where keys are the index of each assistant message, and keys are the ones labeled as either \"Opening Question\" or \"In-depth Question\" categories. len(qs_per_msg) = len(asst_msgs)\n",
    "    asst_sentences_dict : dict\n",
    "    asst_sentences_list : list\n",
    "    total_cost : float\n",
    "        total cost of querying chatgpt\n",
    "    '''\n",
    "    asst_sentences_dict = defaultdict(list)\n",
    "    asst_sentences_list = []\n",
    "    # split sentences in each message\n",
    "    for idx, msg in enumerate(asst_msgs):\n",
    "        asst_sentences_dict[idx] = tokenize.sent_tokenize(msg)\n",
    "        asst_sentences_list.append(msg)\n",
    "    \n",
    "    total_cost = 0\n",
    "    category_per_msg = defaultdict(list)\n",
    "    qs_per_msg = defaultdict(list)\n",
    "    \n",
    "    for msg_num in asst_sentences_dict.keys(): \n",
    "        for msg in asst_sentences_dict[msg_num]:\n",
    "            asst_q_types_prompt = f'''\n",
    "            You will be given a sentence from an interviewer. \n",
    "            Your task is to categorize the following sentence as either an \"Opening Question\", \"In-depth Question\", \"Empathy Statement\", or \"Other\". \n",
    "\n",
    "            \"Opening Question\" is a question that introduces a new concept. \n",
    "            \"In-depth Question\" is a question that builds upon a previous question, such as asking for more specific detail or making a clarification. \n",
    "            \"Empathy Statement\" is a statement that expresses reflection, understanding, or empathy. \n",
    "            \"Other\" sentences would be any that do not fit the previous categories. \n",
    "            \n",
    "            Respond with the category only.\n",
    "\n",
    "            Sentence:\n",
    "            {msg}\n",
    "            '''\n",
    "            content, cost = get_gpt_response([{\"role\": \"user\", \"content\": asst_q_types_prompt}])\n",
    "            total_cost += cost\n",
    "            category_per_msg[msg_num].append(content)\n",
    "            if \"Question\" in content:\n",
    "                qs_per_msg[msg_num].append(content)\n",
    "    \n",
    "    return category_per_msg, qs_per_msg, asst_sentences_dict, asst_sentences_list, total_cost\n",
    "\n",
    "\n",
    "def get_question_category(asst_msgs,opening_questions_str,indepth_questions_str):\n",
    "    '''\n",
    "    return\n",
    "    ------\n",
    "    category_list : list\n",
    "        list of either \"Opening Question\", \"In-depth Question\", \"Empathy Statement\", or \"Other\". Length of list is the number of sentences expressed.\n",
    "    category_per_msg : dict\n",
    "        dict where keys are the index of each assistant message, and keys are the individual sentence categories. len(category_per_msg) = len(asst_msgs)\n",
    "    qs_per_msg : dict\n",
    "        dict where keys are the index of each assistant message, and keys are the ones labeled as either \"Opening Question\" or \"In-depth Question\" categories. len(qs_per_msg) = len(asst_msgs)\n",
    "    asst_sentences_dict : dict\n",
    "    asst_sentences_list : list\n",
    "    total_cost : float\n",
    "        total cost of querying chatgpt\n",
    "    '''\n",
    "    asst_sentences_dict = defaultdict(list)\n",
    "    asst_sentences_list = []\n",
    "    # split sentences in each message\n",
    "    for idx, msg in enumerate(asst_msgs):\n",
    "        asst_sentences_dict[idx] = tokenize.sent_tokenize(msg)\n",
    "        asst_sentences_list.append(msg)\n",
    "    \n",
    "    total_cost = 0\n",
    "    category_per_msg = defaultdict(list)\n",
    "    qs_per_msg = defaultdict(list)\n",
    "    \n",
    "    for msg_num in asst_sentences_dict.keys(): \n",
    "        for msg in asst_sentences_dict[msg_num]: ###TODO: finish prompt engineering\n",
    "            asst_q_types_prompt = f'''\n",
    "            You will be given a question posed during a semi-structured interview.\n",
    "\n",
    "            You will be also given suggested Opening Questions and suggested In-depth Questions that the semi-structured interview follows.\n",
    "\n",
    "            \"Opening Question\" is a question that introduces a new concept.\n",
    "            \"In-depth Question\" is a question that builds upon a previous question, such as asking for more specific detail or making a clarification. \n",
    "\n",
    "            Your task is to categorize the following question as either an \"Opening Question\" or \"In-depth Question\". Use the lists of Suggested Opening and In-Depth Questions for reference to categorize the given question. For example, the question \"What is your date of birth?\" matches with \"date of birth\", which is in the Suggested Opening Questions category. You should respond with \"Opening Question\" in this case. \n",
    "            \n",
    "            Respond with the category only.\n",
    "\n",
    "            Suggested Opening Questions:\n",
    "            {opening_questions_str}\n",
    "\n",
    "            Suggested In-Depth Questions:\n",
    "            {indepth_questions_str}\n",
    "\n",
    "            Question:\n",
    "            {msg}\n",
    "            '''\n",
    "            content, cost = get_gpt_response([{\"role\": \"user\", \"content\": asst_q_types_prompt}])\n",
    "            total_cost += cost\n",
    "            category_per_msg[msg_num].append(content)\n",
    "            if \"Question\" in content:\n",
    "                qs_per_msg[msg_num].append(content)\n",
    "    \n",
    "    return category_per_msg, qs_per_msg, asst_sentences_dict, asst_sentences_list, total_cost\n",
    "\n",
    "# def get_num_asst_qs(qs_per_msg):\n",
    "#     qs_per_msg_list = [len(qs_per_msg[q]) for q in qs_per_msg.keys()]\n",
    "#     total_qs = sum(qs_per_msg_list)\n",
    "#     avg_qs_per_msg = np.average(qs_per_msg_list)\n",
    "#     return total_qs, avg_qs_per_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of opening questions in question bank: 37\n",
      "number of in-depth questions in question bank: 13\n",
      "number of questions in question bank: 50\n"
     ]
    }
   ],
   "source": [
    "question_bank = Path(\"../transcript_generation/prompts/questionbank_v2.txt\").read_text()\n",
    "qb_list = question_bank.split(\"\\n\")[:-1] #remove last question in qb_list, which is a command to end interview\n",
    "\n",
    "filtered_qb_list = [q for q in qb_list if len(q) > 0 and q[0] != \"#\"]\n",
    "print(\"number of opening questions in question bank:\", len([q for q in filtered_qb_list if len(q) > 0 and q[0] == \"-\"]))\n",
    "print(\"number of in-depth questions in question bank:\", len([q for q in filtered_qb_list if len(q) > 0 and q[0] == \"+\"]))\n",
    "# print(filtered_qb_list)\n",
    "print(\"number of questions in question bank:\", len(filtered_qb_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if scraping from analysis.csv\n",
    "initial_analysis_csv_path = \"./analysis.csv\"\n",
    "final_analysis_csv_path = \"./gpt_analysis.csv\"\n",
    "# analysis_df = pd.read_csv(initial_analysis_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['filename', 'is_double_model', 'patient_str', 'is_rambling_prompt',\n",
       "       'total_cost', 'time', 'edge_case', 'user_temp', 'asst_temp', 'temp',\n",
       "       'convo_length', 'convo_rounds', 'asst_utt', ''asst_messages'',\n",
       "       'asst_distinct1', ''asst_msg_len'', 'asst_avg_msg_len', 'user_utt',\n",
       "       ''user_messages'', 'user_distinct1', ''user_msg_len'',\n",
       "       'user_avg_msg_len', ''asst_category_per_msg'', ''asst_qs_per_msg'',\n",
       "       'asst_avg_qs_per_msg', ''asst_sentences_dict'', ''asst_category_list'',\n",
       "       ''asst_qs_list'', 'asst_num_sentences', 'asst_num_qs',\n",
       "       'asst_opening_qs', 'asst_indepth_qs', 'asst_empathy_statements',\n",
       "       'asst_other_statements', 'asst_coverage', ''asst_coverage_content'',\n",
       "       ''user_summary'', 'user_coverage', ''user_coverage_content'',\n",
       "       'analysis_cost', ''user_edge_case_present'',\n",
       "       ''asst_edge_case_present''],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if needing to drop or working with existing data\n",
    "analysis_df = pd.read_csv(final_analysis_csv_path)\n",
    "print(len(analysis_df.keys()))\n",
    "analysis_df.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['filename', 'is_double_model', 'patient_str', 'is_rambling_prompt',\n",
       "       'total_cost', 'time', 'edge_case', 'user_temp', 'asst_temp', 'temp',\n",
       "       'convo_length', 'convo_rounds', 'asst_utt', ''asst_messages'',\n",
       "       'asst_distinct1', ''asst_msg_len'', 'asst_avg_msg_len', 'user_utt',\n",
       "       ''user_messages'', 'user_distinct1', ''user_msg_len'',\n",
       "       'user_avg_msg_len', ''asst_category_per_msg'', ''asst_qs_per_msg'',\n",
       "       'asst_avg_qs_per_msg', ''asst_sentences_dict'', ''asst_category_list'',\n",
       "       ''asst_qs_list'', 'asst_num_sentences', 'asst_num_qs',\n",
       "       'asst_opening_qs', 'asst_indepth_qs', 'asst_empathy_statements',\n",
       "       'asst_other_statements', 'asst_coverage', ''asst_coverage_content'',\n",
       "       ''user_summary'', 'user_coverage', ''user_coverage_content'',\n",
       "       'analysis_cost'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_df = analysis_df.drop(columns=\"'user_edge_case_present'\")\n",
    "analysis_df = analysis_df.drop(columns=\"'asst_edge_case_present'\")\n",
    "print(len(analysis_df.keys()))\n",
    "analysis_df.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant categories are present, skipping\n",
      "assistant message coverage is present, skipping\n",
      "user message summary is present, skipping\n",
      "user message coverage is present, skipping\n",
      "user edge case analysis is present, skipping\n",
      "assistant edge case analysis is present, skipping\n",
      "assistant categories are present, skipping\n",
      "assistant message coverage is present, skipping\n",
      "user message summary is present, skipping\n",
      "user message coverage is present, skipping\n",
      "getting user edge case analysis\n",
      "getting assistant edge case analysis\n",
      "assistant categories are present, skipping\n",
      "assistant message coverage is present, skipping\n",
      "user message summary is present, skipping\n",
      "user message coverage is present, skipping\n",
      "getting user edge case analysis\n",
      "getting assistant edge case analysis\n",
      "assistant categories are present, skipping\n",
      "assistant message coverage is present, skipping\n",
      "user message summary is present, skipping\n",
      "user message coverage is present, skipping\n",
      "getting user edge case analysis\n",
      "getting assistant edge case analysis\n",
      "assistant categories are present, skipping\n",
      "assistant message coverage is present, skipping\n",
      "user message summary is present, skipping\n",
      "user message coverage is present, skipping\n",
      "getting user edge case analysis\n",
      "getting assistant edge case analysis\n",
      "assistant categories are present, skipping\n",
      "assistant message coverage is present, skipping\n",
      "user message summary is present, skipping\n",
      "user message coverage is present, skipping\n",
      "getting user edge case analysis\n",
      "getting assistant edge case analysis\n",
      "assistant categories are present, skipping\n",
      "assistant message coverage is present, skipping\n",
      "user message summary is present, skipping\n",
      "user message coverage is present, skipping\n",
      "getting user edge case analysis\n",
      "getting assistant edge case analysis\n",
      "assistant categories are present, skipping\n",
      "assistant message coverage is present, skipping\n",
      "user message summary is present, skipping\n",
      "user message coverage is present, skipping\n",
      "getting user edge case analysis\n",
      "getting assistant edge case analysis\n",
      "assistant categories are present, skipping\n",
      "assistant message coverage is present, skipping\n",
      "user message summary is present, skipping\n",
      "user message coverage is present, skipping\n",
      "getting user edge case analysis\n",
      "getting assistant edge case analysis\n",
      "assistant categories are present, skipping\n",
      "assistant message coverage is present, skipping\n",
      "user message summary is present, skipping\n",
      "user message coverage is present, skipping\n",
      "getting user edge case analysis\n",
      "getting assistant edge case analysis\n",
      "assistant categories are present, skipping\n",
      "assistant message coverage is present, skipping\n",
      "user message summary is present, skipping\n",
      "user message coverage is present, skipping\n",
      "getting user edge case analysis\n",
      "getting assistant edge case analysis\n",
      "assistant categories are present, skipping\n",
      "assistant message coverage is present, skipping\n",
      "user message summary is present, skipping\n",
      "user message coverage is present, skipping\n",
      "getting user edge case analysis\n",
      "getting assistant edge case analysis\n",
      "assistant categories are present, skipping\n",
      "assistant message coverage is present, skipping\n",
      "user message summary is present, skipping\n",
      "user message coverage is present, skipping\n",
      "getting user edge case analysis\n",
      "getting assistant edge case analysis\n",
      "assistant categories are present, skipping\n",
      "assistant message coverage is present, skipping\n",
      "user message summary is present, skipping\n",
      "user message coverage is present, skipping\n",
      "getting user edge case analysis\n",
      "getting assistant edge case analysis\n",
      "assistant categories are present, skipping\n",
      "assistant message coverage is present, skipping\n",
      "user message summary is present, skipping\n",
      "user message coverage is present, skipping\n",
      "getting user edge case analysis\n",
      "getting assistant edge case analysis\n",
      "assistant categories are present, skipping\n",
      "assistant message coverage is present, skipping\n",
      "user message summary is present, skipping\n",
      "user message coverage is present, skipping\n",
      "getting user edge case analysis\n",
      "getting assistant edge case analysis\n",
      "assistant categories are present, skipping\n",
      "assistant message coverage is present, skipping\n",
      "user message summary is present, skipping\n",
      "user message coverage is present, skipping\n",
      "getting user edge case analysis\n",
      "getting assistant edge case analysis\n",
      "assistant categories are present, skipping\n",
      "assistant message coverage is present, skipping\n",
      "user message summary is present, skipping\n",
      "user message coverage is present, skipping\n",
      "getting user edge case analysis\n",
      "getting assistant edge case analysis\n",
      "assistant categories are present, skipping\n",
      "assistant message coverage is present, skipping\n",
      "user message summary is present, skipping\n",
      "user message coverage is present, skipping\n",
      "getting user edge case analysis\n",
      "getting assistant edge case analysis\n",
      "assistant categories are present, skipping\n",
      "assistant message coverage is present, skipping\n",
      "user message summary is present, skipping\n",
      "user message coverage is present, skipping\n",
      "getting user edge case analysis\n",
      "getting assistant edge case analysis\n",
      "saving file to ./gpt_analysis.csv...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#### NOTE before running: must prompt engineer edge case checking and find a better method for extracting question/statement subtypes\n",
    "\n",
    "for idx, row in analysis_df.iterrows():\n",
    "    # print(transcript_path)\n",
    "    if 'analysis_cost' not in row:\n",
    "        analysis_cost = 0\n",
    "    elif pd.isna(row['analysis_cost']):\n",
    "        analysis_cost = 0\n",
    "    else:\n",
    "        analysis_cost=row['analysis_cost']\n",
    "    \n",
    "    patient_info = row[\"patient_str\"]\n",
    "    patient_msgs = row[\"'user_messages'\"].split(\"|\")\n",
    "    patient_lines = \"\\n\".join([f\"{i}. {line}\" for i, line in enumerate(patient_msgs)])\n",
    "\n",
    "    asst_msgs = row[\"'asst_messages'\"].split(\"|\")\n",
    "    asst_lines = \"\\n\".join([f\"{i}. {line}\" for i, line in enumerate(asst_msgs)])\n",
    "\n",
    "    try:\n",
    "        ### find data about assistant\n",
    "        if \"'asst_category_per_msg'\" not in analysis_df.columns or pd.isnull(row[\"'asst_category_per_msg'\"]):\n",
    "            print(\"getting assistant message categories...\")\n",
    "            category_per_msg, qs_per_msg, asst_sentences_dict, asst_sentences_list, category_cost = get_sentence_category(asst_msgs)\n",
    "\n",
    "            ###save category per message\n",
    "            analysis_df.at[idx, \"'asst_category_per_msg'\"] = f'{dict(category_per_msg)}'\n",
    "\n",
    "            ###save questions per message\n",
    "            analysis_df.at[idx, \"'asst_qs_per_msg'\"] = f'{dict(qs_per_msg)}'\n",
    "            qs_per_msg_list = [len(qs_per_msg[q]) for q in qs_per_msg.keys()]\n",
    "            analysis_df.at[idx, \"asst_avg_qs_per_msg\"] = np.average(qs_per_msg_list)\n",
    "\n",
    "            ###save sentence per message\n",
    "            analysis_df.at[idx, \"'asst_sentences_dict'\"] = f'{asst_sentences_dict}'\n",
    "\n",
    "            analysis_cost += category_cost \n",
    "\n",
    "            category_list = [c for cs in category_per_msg.values() for c in cs]\n",
    "            qs_list = [q for qs in qs_per_msg.values() for q in qs]\n",
    "            analysis_df.at[idx, \"'asst_category_list'\"] = f'{category_list}'\n",
    "            analysis_df.at[idx, \"'asst_qs_list'\"] = f'{qs_list}'\n",
    "\n",
    "            analysis_df.at[idx, \"asst_num_sentences\"] = len(asst_sentences_list)\n",
    "            analysis_df.at[idx, \"asst_num_qs\"] = len(qs_list)\n",
    "\n",
    "            num_opening_qs = len([q for q in category_list if q == \"Opening Question\"])\n",
    "            num_indepth_qs = len([q for q in category_list if q == 'In-depth Question'])\n",
    "            analysis_df.at[idx, \"asst_opening_qs\"] = num_opening_qs\n",
    "            analysis_df.at[idx, \"asst_indepth_qs\"] = num_indepth_qs\n",
    "            analysis_df.at[idx, \"asst_empathy_statements\"] = len([q for q in category_list if q == 'Empathy Statement'])\n",
    "            analysis_df.at[idx, \"asst_other_statements\"] = len([q for q in category_list if q == 'Other'])\n",
    "        else:\n",
    "            print(\"assistant categories are present, skipping\")\n",
    "    except Exception as e:\n",
    "        print(e, \"occurred during get_sentence_category()\")\n",
    "        break\n",
    "\n",
    "    try:\n",
    "        if 'asst_coverage' not in analysis_df.columns or pd.isnull(row['asst_coverage']):\n",
    "            print(\"getting assistant message coverage...\")\n",
    "            asst_cov_content, asst_cov_specificity_val, asst_cov_cost = get_asst_coverage(filtered_qb_list, asst_msgs)\n",
    "            analysis_df.at[idx, \"asst_coverage\"] = asst_cov_specificity_val\n",
    "            analysis_df.at[idx, \"'asst_coverage_content'\"] = asst_cov_content\n",
    "            analysis_cost += asst_cov_cost\n",
    "        else:\n",
    "            print(\"assistant message coverage is present, skipping\")\n",
    "    except Exception as e:\n",
    "        print(e, \"occurred during get_asst_coverage()\")\n",
    "        break\n",
    "    try:\n",
    "        if \"'user_summary'\" not in analysis_df.columns or pd.isnull(row[\"'user_summary'\"]):\n",
    "            print(\"getting user message summary...\")\n",
    "            usr_summary_content, usr_summary_cost = get_user_summary(patient_lines)\n",
    "            analysis_df.at[idx, \"'user_summary'\"] = usr_summary_content\n",
    "            analysis_cost += usr_summary_cost\n",
    "        else:\n",
    "            print(\"user message summary is present, skipping\")\n",
    "    except Exception as e:\n",
    "        print(e, \"occurred during get_user_summary()\")\n",
    "        break\n",
    "    \n",
    "    try:\n",
    "        if \"user_coverage\" not in row or pd.isna(row[\"user_coverage\"]):\n",
    "            print(\"getting user message coverage...\")\n",
    "            usr_cov_content, usr_cov_val, usr_cov_cost = get_user_coverage(patient_info, usr_summary_content)\n",
    "            analysis_df.at[idx, 'user_coverage'] = usr_cov_val\n",
    "            analysis_df.at[idx, \"'user_coverage_content'\"] = usr_cov_content\n",
    "            analysis_cost += usr_cov_cost\n",
    "        else:\n",
    "            print(\"user message coverage is present, skipping\")\n",
    "    except Exception as e:\n",
    "        print(e, \"occurred during get_user_coverage()\")\n",
    "        break\n",
    "\n",
    "    try:\n",
    "        if \"'user_edge_case_present'\" not in analysis_df.columns or pd.isnull(row[\"'user_edge_case_present'\"]):\n",
    "            print(\"getting user edge case analysis\")\n",
    "            usr_edgecase_content, usr_edgecase_cost = get_user_edge_case_present(patient_lines)\n",
    "            analysis_df.at[idx, \"'user_edge_case_present'\"] = usr_edgecase_content\n",
    "            analysis_cost += usr_edgecase_cost\n",
    "        else:\n",
    "            print(\"user edge case analysis is present, skipping\")\n",
    "    except Exception as e:\n",
    "        print(e, \"occurred during get_user_edge_case_present(). Try running the cell again.\")\n",
    "        break\n",
    "\n",
    "    try: \n",
    "        if \"'asst_edge_case_present'\" not in analysis_df.columns or pd.isnull(row[\"'asst_edge_case_present'\"]):\n",
    "            print(\"getting assistant edge case analysis\")\n",
    "            asst_edgecase_content, asst_edgecase_cost = get_asst_edge_case_present(asst_lines)\n",
    "            analysis_df.at[idx, \"'asst_edge_case_present'\"] = asst_edgecase_content\n",
    "            analysis_cost += asst_edgecase_cost\n",
    "        else:\n",
    "            print(\"assistant edge case analysis is present, skipping\")\n",
    "    except Exception as e:\n",
    "        print(e, \"occurred during get_asst_edge_case_present(). Try running the cell again.\")\n",
    "        break\n",
    "\n",
    "\n",
    "    analysis_df.at[idx, 'analysis_cost'] = analysis_cost\n",
    "    \n",
    "\n",
    "print(f\"saving file to {final_analysis_csv_path}...\")\n",
    "analysis_df.to_csv(final_analysis_csv_path,index=False)\n",
    "print(f\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# closer look at categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['filename', 'is_double_model', 'patient_str', 'is_rambling_prompt',\n",
       "       'total_cost', 'time', 'edge_case', 'user_temp', 'asst_temp', 'temp',\n",
       "       'convo_length', 'convo_rounds', 'asst_utt', ''asst_messages'',\n",
       "       'asst_distinct1', ''asst_msg_len'', 'asst_avg_msg_len', 'user_utt',\n",
       "       ''user_messages'', 'user_distinct1', ''user_msg_len'',\n",
       "       'user_avg_msg_len', ''asst_category_per_msg'', ''asst_qs_per_msg'',\n",
       "       'asst_avg_qs_per_msg', ''asst_sentences_dict'', ''asst_category_list'',\n",
       "       ''asst_qs_list'', 'asst_num_sentences', 'asst_num_qs',\n",
       "       'asst_opening_qs', 'asst_indepth_qs', 'asst_empathy_statements',\n",
       "       'asst_other_statements', 'asst_coverage', ''asst_coverage_content'',\n",
       "       ''user_summary'', 'user_coverage', ''user_coverage_content'',\n",
       "       'analysis_cost', ''user_edge_case_present'',\n",
       "       ''asst_edge_case_present''],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_analysis_path = \"./gpt_analysis.csv\"\n",
    "gpt_df = pd.read_csv(gpt_analysis_path)\n",
    "gpt_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DM_20240428-221529_Interview.json\n"
     ]
    }
   ],
   "source": [
    "print(gpt_df[\"filename\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"defaultdict(<class 'list'>, {0: ['Great, thank you for your cooperation.', \"\n",
      " '\"Let\\'s start with some general information.\", \\'Could you please tell me '\n",
      " 'your full name?\\'], 1: [\\'Thank you, Deborah.\\', \"Do you have a preferred '\n",
      " 'name you\\'d like us to use?\"], 2: [\\'Alright, Deb.\\', \\'What is your date of '\n",
      " \"birth?'], 3: ['Thank you.', 'May I know your sex?'], 4: ['Got it.', 'Can you \"\n",
      " \"tell me your current city or town of residence?'], 5: ['Thank you, Deb.', \"\n",
      " \"'Are you currently single, married, or in a common-law relationship?'], 6: \"\n",
      " '[\"I\\'m sorry for your loss.\", \\'Do you have any children or dependents?\\'], '\n",
      " \"7: ['Understood.', 'Are you currently working?'], 8: ['That sounds like an \"\n",
      " \"interesting job.', 'How long have you been working as a sports development \"\n",
      " 'officer?\\'], 9: [\"That\\'s quite a tenure.\", \\'Have you ever been on '\n",
      " \"disability assistance?'], 10: ['Good to know.', 'What about your handedness \"\n",
      " \"- are you left-handed, right-handed, or ambidextrous?'], 11: ['Thank you for \"\n",
      " \"sharing.', 'Could you tell me about your current doctors?'], 12: ['I \"\n",
      " 'understand that it can be difficult to feel understood.\\', \"It\\'s important '\n",
      " 'to have healthcare professionals you feel comfortable with.\", \\'Do you have '\n",
      " 'any known allergies?\\'], 13: [\"Noted, I\\'ll make sure Dr. Phillips is aware '\n",
      " 'of your allergies.\", \"Could you tell me about any current medications and '\n",
      " 'their dosages that you\\'re taking?\"], 14: [\"That\\'s alright, you\\'re likely '\n",
      " 'referring to Clonazepam.\", \"Do you know the dosage you\\'re currently '\n",
      " 'taking?\"], 15: [\"Understood, it\\'s helpful to have that detail.\", \\'Are you '\n",
      " \"taking any health supplements?'], 16: ['Got it, thank you.', 'How often do \"\n",
      " \"you use nicotine, marijuana, or alcohol?'], 17: ['Thank you for being open \"\n",
      " 'about your usage.\\', \"Let\\'s move on to your medical history.\", \"Can you '\n",
      " \"tell me about any health conditions or diagnoses you've had, including \"\n",
      " 'details such as when you were diagnosed?\"], 18: [\\'Thank you for sharing '\n",
      " \"that.', 'Have you had any previous hospitalizations or surgeries?'], 19: \"\n",
      " '[\"That\\'s good to hear.\", \\'Have you ever had any head injuries or '\n",
      " 'concussions?\\'], 20: [\"I\\'m glad to hear you\\'ve been safe.\", \\'Have you '\n",
      " \"ever had a history of seizures?'], 21: ['Great, that simplifies things.', \"\n",
      " \"'Have you ever been in rehab or received substance counseling?'], 22: \"\n",
      " \"['Understood.', 'Have you seen any other medical professionals for your \"\n",
      " 'health?\\', \\'If yes, could you tell me who, when, and why?\\'], 23: [\"It\\'s '\n",
      " 'important to feel heard by your healthcare providers.\", \"I\\'ll make sure to '\n",
      " 'note your feelings about this.\", \"Let\\'s shift to your family history.\", '\n",
      " \"'Is there a history of psychiatric conditions in other family members?', 'If \"\n",
      " 'yes, who and did they receive treatment or hospital care?\\'], 24: [\"It '\n",
      " 'sounds like mental health challenges have touched your family, but I '\n",
      " 'appreciate the resilience you\\'re showing.\", \\'Is there a family history of '\n",
      " \"neurological or genetic conditions?'], 25: ['Thank you for clarifying.', 'Do \"\n",
      " \"you have any siblings besides the brother you mentioned?', 'If yes, could \"\n",
      " 'you provide their basic info such as name, age, where they live, and '\n",
      " \"occupation?'], 26: ['Thank you for sharing that.', 'It helps to have a \"\n",
      " 'picture of your family structure.\\', \"Now, let\\'s talk about your personal '\n",
      " 'history.\", \\'Where were you born?\\'], 27: [\"It\\'s great to have such strong '\n",
      " 'roots in one place.\", \\'Are you a Canadian citizen?\\'], 28: [\\'Thank you for '\n",
      " \"confirming.', 'Were there any complications during your birth?'], 29: \"\n",
      " '[\"That\\'s good to hear.\", \\'As a child, did you walk, talk, and develop '\n",
      " 'friendships like other kids your age?\\'], 30: [\"It\\'s quite common to have a '\n",
      " 'smaller circle of close friends.\", \\'How about your experiences in '\n",
      " 'elementary school?\\', \\'Did you face any difficulties?\\'], 31: [\"It\\'s good '\n",
      " 'to hear you were able to catch up.\", \\'Did you experience any traumatic '\n",
      " 'events growing up?\\'], 32: [\"I\\'m sorry to hear about those experiences, '\n",
      " 'especially losing your dad at a young age and the car accident.\", \"It\\'s '\n",
      " 'understandable how such events could have a lasting impact.\", \\'Moving on to '\n",
      " 'a lighter topic, what was your average mark and favorite subject or class in '\n",
      " 'high school?\\'], 33: [\"It\\'s great that you found something you enjoyed and '\n",
      " 'excelled in.\", \\'Did you pursue further education after high school?\\', \\'If '\n",
      " \"yes, where and what type of studies?'], 34: ['That sounds like a perfect \"\n",
      " \"blend of your interests and practical skills.', 'Could you share a bit about \"\n",
      " 'your previous work history, including companies and years of work, before '\n",
      " 'your current position?\\'], 35: [\"It\\'s clear you have a strong passion for '\n",
      " 'sports and have built a career around it.\", \\'Have you had any previous '\n",
      " 'marriages or long-term relationships?\\'], 36: [\"I\\'m truly sorry for your '\n",
      " 'loss.\", \\'It sounds like you had a meaningful partnership.\\', \"It\\'s '\n",
      " 'understandable how challenging navigating life after such a loss can be.\", '\n",
      " \"'On a different note, what are some hobbies or activities you enjoy?'], 37: \"\n",
      " '[\"It sounds like you\\'ve found some beautiful ways to stay active and find '\n",
      " 'peace.\", \\'How do you like to relax on a stressful day?\\'], 38: [\"It\\'s '\n",
      " 'important to have strategies that help you unwind and cope with stress.\", '\n",
      " '\\'Thank you for sharing your methods with me.\\', \"Lastly, is there anything '\n",
      " 'specific you think the doctor needs to know that we haven\\'t covered yet?\"], '\n",
      " '39: [\"Your feelings are completely valid, and it\\'s understandable to seek '\n",
      " 'more stability.\", \"I\\'ll make sure to convey this to Dr. Phillips, '\n",
      " 'emphasizing your desire for steadiness and how the panic can feel '\n",
      " 'overwhelming at times.\", \\'Thank you for being open and sharing your '\n",
      " \"experiences with me.', 'Your insights are invaluable for understanding your \"\n",
      " 'needs and how best to support you.\\', \"If there\\'s nothing else, I believe '\n",
      " 'we have covered everything necessary for now.\", \\'Thank you, and '\n",
      " \"goodbye.']})\")\n"
     ]
    }
   ],
   "source": [
    "pprint(gpt_df[\"'asst_sentences_dict'\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, \n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#isolating the things that we want to remove\n",
    "print(gpt_df[\"'asst_sentences_dict'\"][0][:28])\n",
    "print(gpt_df[\"'asst_sentences_dict'\"][0][-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "asst_category_list = ast.literal_eval(gpt_df[\"'asst_category_list'\"][0])\n",
    "asst_sentences_dict = ast.literal_eval(gpt_df[\"'asst_sentences_dict'\"][0][28:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "asst_sentences = [x for v in asst_sentences_dict.values() for x in v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Other', 'Great, thank you for your cooperation.'),\n",
       " ('Opening Question', \"Let's start with some general information.\"),\n",
       " ('Opening Question', 'Could you please tell me your full name?'),\n",
       " ('Other', 'Thank you, Deborah.'),\n",
       " ('Opening Question', \"Do you have a preferred name you'd like us to use?\"),\n",
       " ('Other', 'Alright, Deb.'),\n",
       " ('Opening Question', 'What is your date of birth?'),\n",
       " ('Other', 'Thank you.'),\n",
       " ('Other', 'May I know your sex?'),\n",
       " ('Other', 'Got it.'),\n",
       " ('Opening Question',\n",
       "  'Can you tell me your current city or town of residence?'),\n",
       " ('Other', 'Thank you, Deb.'),\n",
       " ('Opening Question',\n",
       "  'Are you currently single, married, or in a common-law relationship?'),\n",
       " ('Empathy Statement', \"I'm sorry for your loss.\"),\n",
       " ('Opening Question', 'Do you have any children or dependents?'),\n",
       " ('Other', 'Understood.'),\n",
       " ('Opening Question', 'Are you currently working?'),\n",
       " ('Empathy Statement', 'That sounds like an interesting job.'),\n",
       " ('In-depth Question',\n",
       "  'How long have you been working as a sports development officer?'),\n",
       " ('Empathy Statement', \"That's quite a tenure.\"),\n",
       " ('Opening Question', 'Have you ever been on disability assistance?'),\n",
       " ('Other', 'Good to know.'),\n",
       " ('In-depth Question',\n",
       "  'What about your handedness - are you left-handed, right-handed, or ambidextrous?'),\n",
       " ('Empathy Statement', 'Thank you for sharing.'),\n",
       " ('In-depth Question', 'Could you tell me about your current doctors?'),\n",
       " ('Empathy Statement',\n",
       "  'I understand that it can be difficult to feel understood.'),\n",
       " ('Empathy Statement',\n",
       "  \"It's important to have healthcare professionals you feel comfortable with.\"),\n",
       " ('Opening Question', 'Do you have any known allergies?'),\n",
       " ('Empathy Statement',\n",
       "  \"Noted, I'll make sure Dr. Phillips is aware of your allergies.\"),\n",
       " ('In-depth Question',\n",
       "  \"Could you tell me about any current medications and their dosages that you're taking?\"),\n",
       " ('Empathy Statement',\n",
       "  \"That's alright, you're likely referring to Clonazepam.\"),\n",
       " ('In-depth Question', \"Do you know the dosage you're currently taking?\"),\n",
       " ('Empathy Statement', \"Understood, it's helpful to have that detail.\"),\n",
       " ('Opening Question', 'Are you taking any health supplements?'),\n",
       " ('Other', 'Got it, thank you.'),\n",
       " ('In-depth Question',\n",
       "  'How often do you use nicotine, marijuana, or alcohol?'),\n",
       " ('Empathy Statement', 'Thank you for being open about your usage.'),\n",
       " ('Opening Question', \"Let's move on to your medical history.\"),\n",
       " ('In-depth Question',\n",
       "  \"Can you tell me about any health conditions or diagnoses you've had, including details such as when you were diagnosed?\"),\n",
       " ('Empathy Statement', 'Thank you for sharing that.'),\n",
       " ('Opening Question',\n",
       "  'Have you had any previous hospitalizations or surgeries?'),\n",
       " ('Empathy Statement', \"That's good to hear.\"),\n",
       " ('Opening Question', 'Have you ever had any head injuries or concussions?'),\n",
       " ('Empathy Statement', \"I'm glad to hear you've been safe.\"),\n",
       " ('In-depth Question', 'Have you ever had a history of seizures?'),\n",
       " ('Other', 'Great, that simplifies things.'),\n",
       " ('In-depth Question',\n",
       "  'Have you ever been in rehab or received substance counseling?'),\n",
       " ('Empathy Statement', 'Understood.'),\n",
       " ('In-depth Question',\n",
       "  'Have you seen any other medical professionals for your health?'),\n",
       " ('In-depth Question', 'If yes, could you tell me who, when, and why?'),\n",
       " ('Empathy Statement',\n",
       "  \"It's important to feel heard by your healthcare providers.\"),\n",
       " ('Empathy Statement', \"I'll make sure to note your feelings about this.\"),\n",
       " ('Opening Question', \"Let's shift to your family history.\"),\n",
       " ('In-depth Question',\n",
       "  'Is there a history of psychiatric conditions in other family members?'),\n",
       " ('In-depth Question',\n",
       "  'If yes, who and did they receive treatment or hospital care?'),\n",
       " ('Empathy Statement',\n",
       "  \"It sounds like mental health challenges have touched your family, but I appreciate the resilience you're showing.\"),\n",
       " ('In-depth Question',\n",
       "  'Is there a family history of neurological or genetic conditions?'),\n",
       " ('Empathy Statement', 'Thank you for clarifying.'),\n",
       " ('In-depth Question',\n",
       "  'Do you have any siblings besides the brother you mentioned?'),\n",
       " ('In-depth Question',\n",
       "  'If yes, could you provide their basic info such as name, age, where they live, and occupation?'),\n",
       " ('Empathy Statement', 'Thank you for sharing that.'),\n",
       " ('Other', 'It helps to have a picture of your family structure.'),\n",
       " ('Opening Question', \"Now, let's talk about your personal history.\"),\n",
       " ('Opening Question', 'Where were you born?'),\n",
       " ('Empathy Statement', \"It's great to have such strong roots in one place.\"),\n",
       " ('Opening Question', 'Are you a Canadian citizen?'),\n",
       " ('Other', 'Thank you for confirming.'),\n",
       " ('In-depth Question', 'Were there any complications during your birth?'),\n",
       " ('Empathy Statement', \"That's good to hear.\"),\n",
       " ('In-depth Question',\n",
       "  'As a child, did you walk, talk, and develop friendships like other kids your age?'),\n",
       " ('Empathy Statement',\n",
       "  \"It's quite common to have a smaller circle of close friends.\"),\n",
       " ('In-depth Question', 'How about your experiences in elementary school?'),\n",
       " ('In-depth Question', 'Did you face any difficulties?'),\n",
       " ('Empathy Statement', \"It's good to hear you were able to catch up.\"),\n",
       " ('In-depth Question', 'Did you experience any traumatic events growing up?'),\n",
       " ('Empathy Statement',\n",
       "  \"I'm sorry to hear about those experiences, especially losing your dad at a young age and the car accident.\"),\n",
       " ('Empathy Statement',\n",
       "  \"It's understandable how such events could have a lasting impact.\"),\n",
       " ('Opening Question',\n",
       "  'Moving on to a lighter topic, what was your average mark and favorite subject or class in high school?'),\n",
       " ('Empathy Statement',\n",
       "  \"It's great that you found something you enjoyed and excelled in.\"),\n",
       " ('Opening Question', 'Did you pursue further education after high school?'),\n",
       " ('In-depth Question', 'If yes, where and what type of studies?'),\n",
       " ('Empathy Statement',\n",
       "  'That sounds like a perfect blend of your interests and practical skills.'),\n",
       " ('Opening Question',\n",
       "  'Could you share a bit about your previous work history, including companies and years of work, before your current position?'),\n",
       " ('Empathy Statement',\n",
       "  \"It's clear you have a strong passion for sports and have built a career around it.\"),\n",
       " ('In-depth Question',\n",
       "  'Have you had any previous marriages or long-term relationships?'),\n",
       " ('Empathy Statement', \"I'm truly sorry for your loss.\"),\n",
       " ('Empathy Statement', 'It sounds like you had a meaningful partnership.'),\n",
       " ('Empathy Statement',\n",
       "  \"It's understandable how challenging navigating life after such a loss can be.\"),\n",
       " ('Opening Question',\n",
       "  'On a different note, what are some hobbies or activities you enjoy?'),\n",
       " ('Empathy Statement',\n",
       "  \"It sounds like you've found some beautiful ways to stay active and find peace.\"),\n",
       " ('Opening Question', 'How do you like to relax on a stressful day?'),\n",
       " ('Other',\n",
       "  \"It's important to have strategies that help you unwind and cope with stress.\"),\n",
       " ('Empathy Statement', 'Thank you for sharing your methods with me.'),\n",
       " ('In-depth Question',\n",
       "  \"Lastly, is there anything specific you think the doctor needs to know that we haven't covered yet?\"),\n",
       " ('Empathy Statement',\n",
       "  \"Your feelings are completely valid, and it's understandable to seek more stability.\"),\n",
       " ('Empathy Statement',\n",
       "  \"I'll make sure to convey this to Dr. Phillips, emphasizing your desire for steadiness and how the panic can feel overwhelming at times.\"),\n",
       " ('Empathy Statement',\n",
       "  'Thank you for being open and sharing your experiences with me.'),\n",
       " ('Empathy Statement',\n",
       "  'Your insights are invaluable for understanding your needs and how best to support you.'),\n",
       " ('Other',\n",
       "  \"If there's nothing else, I believe we have covered everything necessary for now.\"),\n",
       " ('Other', 'Thank you, and goodbye.')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(asst_category_list[i], asst_sentences[i]) for i in range(len(asst_category_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "asst_questions_only = [i for i in range(len(asst_category_list)) if \"Question\" in asst_category_list[i]]\n",
    "id_questions_only = [i for i in range(len(asst_category_list)) if \"In-depth\" in asst_category_list[i]]\n",
    "o_questions_only = [i for i in range(len(asst_category_list)) if \"Open\" in asst_category_list[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['How long have you been working as a sports development officer?',\n",
       " 'What about your handedness - are you left-handed, right-handed, or ambidextrous?',\n",
       " 'Could you tell me about your current doctors?',\n",
       " \"Could you tell me about any current medications and their dosages that you're taking?\",\n",
       " \"Do you know the dosage you're currently taking?\",\n",
       " 'How often do you use nicotine, marijuana, or alcohol?',\n",
       " \"Can you tell me about any health conditions or diagnoses you've had, including details such as when you were diagnosed?\",\n",
       " 'Have you ever had a history of seizures?',\n",
       " 'Have you ever been in rehab or received substance counseling?',\n",
       " 'Have you seen any other medical professionals for your health?',\n",
       " 'If yes, could you tell me who, when, and why?',\n",
       " 'Is there a history of psychiatric conditions in other family members?',\n",
       " 'If yes, who and did they receive treatment or hospital care?',\n",
       " 'Is there a family history of neurological or genetic conditions?',\n",
       " 'Do you have any siblings besides the brother you mentioned?',\n",
       " 'If yes, could you provide their basic info such as name, age, where they live, and occupation?',\n",
       " 'Were there any complications during your birth?',\n",
       " 'As a child, did you walk, talk, and develop friendships like other kids your age?',\n",
       " 'How about your experiences in elementary school?',\n",
       " 'Did you face any difficulties?',\n",
       " 'Did you experience any traumatic events growing up?',\n",
       " 'If yes, where and what type of studies?',\n",
       " 'Have you had any previous marriages or long-term relationships?',\n",
       " \"Lastly, is there anything specific you think the doctor needs to know that we haven't covered yet?\"]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[asst_sentences[i] for i in id_questions_only]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "#16 opening questions\n",
    "print(len(o_questions_only))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Let's start with some general information.\",\n",
       " 'Could you please tell me your full name?',\n",
       " \"Do you have a preferred name you'd like us to use?\",\n",
       " 'What is your date of birth?',\n",
       " 'Can you tell me your current city or town of residence?',\n",
       " 'Are you currently single, married, or in a common-law relationship?',\n",
       " 'Do you have any children or dependents?',\n",
       " 'Are you currently working?',\n",
       " 'Have you ever been on disability assistance?',\n",
       " 'Do you have any known allergies?',\n",
       " 'Are you taking any health supplements?',\n",
       " \"Let's move on to your medical history.\",\n",
       " 'Have you had any previous hospitalizations or surgeries?',\n",
       " 'Have you ever had any head injuries or concussions?',\n",
       " \"Let's shift to your family history.\",\n",
       " \"Now, let's talk about your personal history.\",\n",
       " 'Where were you born?',\n",
       " 'Are you a Canadian citizen?',\n",
       " 'Moving on to a lighter topic, what was your average mark and favorite subject or class in high school?',\n",
       " 'Did you pursue further education after high school?',\n",
       " 'Could you share a bit about your previous work history, including companies and years of work, before your current position?',\n",
       " 'On a different note, what are some hobbies or activities you enjoy?',\n",
       " 'How do you like to relax on a stressful day?']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[asst_sentences[i] for i in o_questions_only]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Great, thank you for your cooperation.', 'Thank you, Deborah.', 'Alright, Deb.', 'Thank you.', 'May I know your sex?', 'Got it.', 'Thank you, Deb.', 'Understood.', 'Good to know.', 'Got it, thank you.', 'Great, that simplifies things.', 'It helps to have a picture of your family structure.', 'Thank you for confirming.', \"It's important to have strategies that help you unwind and cope with stress.\", \"If there's nothing else, I believe we have covered everything necessary for now.\", 'Thank you, and goodbye.']\n"
     ]
    }
   ],
   "source": [
    "other_only = [i for i in range(len(asst_category_list)) if \"Other\" in asst_category_list[i]]\n",
    "print([asst_sentences[i] for i in other_only])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
